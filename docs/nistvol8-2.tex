\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[9pt,]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={NIST BDRA Volume 8},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


\title{NIST BDRA Volume 8}
\date{}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\hypertarget{nistvol8-2.md}{%
\subsection{nistvol8-2.md}\label{nistvol8-2.md}}

header-includes: - \usepackage[margins=raggedright]{floatrow} ---

\textbf{NIST Special Publication 1500-9}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{DRAFT}\NormalTok{ NIST Big Data Interoperability Framework:}
\ExtensionTok{Volume}\NormalTok{ 8, Reference}
\ExtensionTok{Architecture}\NormalTok{ Interfaces}
\end{Highlighting}
\end{Shaded}

NIST Big Data Public Working Group

Reference Architecture Subgroup

Version 3.0.1

December 1, 2018

\url{https://bigdatawg.nist.gov/V2_output_docs.php}

\includegraphics{images/nist.png}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

NIST Special Publication 1500-9

Information Technology Laboratory

\textbf{DRAFT NIST Big Data Interoperability Framework:}

\textbf{Volume 8, Reference Architecture Interfaces}

\textbf{Version 2}

NIST Big Data Public Working Group (NBD-PWG)

Definitions and Taxonomies Subgroup

National Institute of Standards and Technology

Gaithersburg, MD 20899

This draft publication is available free of charge from:

\url{https://bigdatawg.nist.gov/V2_output_docs.php}

October 2017

\begin{figure}
\centering
\includegraphics{images/us-dept-of-com.png}
\caption{http://physics.nist.gov/Images/doc.bw.gif}
\end{figure}

U. S. Department of Commerce

\emph{Wilbur L. Ross, Jr., Secretary}

National Institute of Standards and Technology

\emph{Dr.~Kent Rochford, Acting Under Secretary of Commerce for
Standards and Technology and Acting NIST Director}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\textbf{National Institute of Standards and Technology (NIST) Special
Publication 1500-9}

?? pages (December 1, 2018)

NIST Special Publication series 1500 is intended to capture external
perspectives related to NIST standards, measurement, and testing-related
efforts. These external perspectives can come from industry, academia,
government, and others. These reports are intended to document external
perspectives and do not represent official NIST positions.

Certain commercial entities, equipment, or materials may be identified
in this document to describe an experimental procedure or concept
adequately. Such identification is not intended to imply recommendation
or endorsement by NIST, nor is it intended to imply that the entities,
materials, or equipment are necessarily the best available for the
purpose.

There may be references in this publication to other publications
currently under development by NIST in accordance with its assigned
statutory responsibilities. The information in this publication,
including concepts and methodologies, may be used by federal agencies
even before the completion of such companion publications. Thus, until
each publication is completed, current requirements, guidelines, and
procedures, where they exist, remain operative. For planning and
transition purposes, federal agencies may wish to closely follow the
development of these new publications by NIST.

Organizations are encouraged to review all draft publications during
public comment periods and provide feedback to NIST. All NIST
publications are available at
\url{http://www.nist.gov/publication-portal.cfm}.

\textbf{Comments on this publication may be submitted to Wo Chang}

National Institute of Standards and Technology

Attn: Wo Chang, Information Technology Laboratory

100 Bureau Drive (Mail Stop 8900) Gaithersburg, MD 20899-8930

Email:
\href{mailto:SP1500comments@nist.gov}{\nolinkurl{SP1500comments@nist.gov}}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

Reports on Computer Systems Technology

The Information Technology Laboratory (ITL) at NIST promotes the U.S.
economy and public welfare by providing technical leadership for the
Nation's measurement and standards infrastructure. ITL develops tests,
test methods, reference data, proof of concept implementations, and
technical analyses to advance the development and productive use of
information technology. ITL's responsibilities include the development
of management, administrative, technical, and physical standards and
guidelines for the cost-effective security and privacy of other than
national security-related information in federal information systems.
This document reports on ITL's research, guidance, and outreach efforts
in Information Technology and its collaborative activities with
industry, government, and academic organizations.

\hypertarget{abstract}{%
\section{Abstract}\label{abstract}}

This document summarizes interfaces that are instrumental for the
interaction with Clouds, Containers, and High Performance Computing
(HPC) systems to manage virtual clusters to support the NIST Big Data
Reference Architecture (NBDRA). The REpresentational State Transfer
(REST) paradigm is used to define these interfaces, allowing easy
integration and adoption by a wide variety of frameworks.

Big Data is a term used to describe extensive datasets, primarily in the
characteristics of volume, variety, velocity, and/or variability. While
opportunities exist with Big Data, the data characteristics can
overwhelm traditional technical approaches, and the growth of data is
outpacing scientific and technological advances in data analytics. To
advance progress in Big Data, the NIST Big Data Public Working Group
(NBD-PWG) is working to develop consensus on important fundamental
concepts related to Big Data. The results are reported in the \emph{NIST
Big Data Interoperability Framework (NBDIF)} series of volumes. This
volume, Volume 8, uses the work performed by the NBD-PWG to identify
objects instrumental for the NIST Big Data Reference Architecture
(NBDRA) which is introduced in the NBDIF: Volume 6, \emph{Reference
Architecture}.

\hypertarget{keywords}{%
\section{Keywords}\label{keywords}}

Adoption; barriers; implementation; interfaces; market maturity;
organizational maturity; project maturity; system modernization.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{acknowledgements}{%
\section{Acknowledgements}\label{acknowledgements}}

This document reflects the contributions and discussions by the
membership of the NBD-PWG, cochaired by Wo Chang (NIST ITL), Bob Marcus
(ET-Strategies), and Chaitan Baru (San Diego Supercomputer Center;
National Science Foundation). For all versions, the Subgroups were led
by the following people: Nancy Grady (SAIC), Natasha Balac (SDSC), and
Eugene Luster (R2AD) for the Definitions and Taxonomies Subgroup;
Geoffrey Fox (Indiana University) and Tsegereda Beyene (Cisco Systems)
for the Use Cases and Requirements Subgroup; Arnab Roy (Fujitsu), Mark
Underwood (Krypton Brothers; Synchrony Financial), and Akhil Manchanda
(GE) for the Security and Privacy Subgroup; David Boyd (InCadence
Strategic Solutions), Orit Levin (Microsoft), Don Krapohl (Augmented
Intelligence), and James Ketner (AT\&T) for the Reference Architecture
Subgroup; and Russell Reinsch (Center for Government Interoperability),
David Boyd (InCadence Strategic Solutions), Carl Buffington (Vistronix),
and Dan McClary (Oracle), for the Standards Roadmap Subgroup.

The editors for this document were the following:

\begin{itemize}
\item
  \textbf{\emph{Version 2.1}}: A previous volume used just the
  definition of the schema based on examples it was easier to read but
  did only include the definition of the resources and not the
  interaction with the resources. This volume was in place till June
  2018.
\item
  \textbf{\emph{Version 2.2}}: This version was significantly changed
  and uses now OpenAPI to specify the Interfaces between the various
  services and components. Editors of this volume are:
\item
  \textbf{\emph{Version 2.3}}: The version includes the
\end{itemize}

Gregor von Laszewski (Indiana University), and Wo Chang (NIST).

Laurie Aldape (Energetics Incorporated) provided editorial assistance
across all NBDIF volumes.

NIST SP 1500-9, Draft NIST Big Data Interoperability Framework: Volume
8, Reference Architecture Interfaces, Version 2 has been collaboratively
authored by the NBD-PWG. As of the date of publication, there are over
six hundred NBD-PWG participants from industry, academia, and
government. Federal agency participants include the National Archives
and Records Administration (NARA), National Aeronautics and Space
Administration (NASA), National Science Foundation (NSF), and the U.S.
Departments of Agriculture, Commerce, Defense, Energy, Census, Health
and Human Services, Homeland Security, Transportation, Treasury, and
Veterans Affairs.

NIST would like to acknowledge the specific contributions to this
volume, during Version 1 and/or Version 2 activities.
\emph{Contributors} are members of the NIST Big Data Public Working
Group who dedicated great effort to prepare and gave substantial time on
a regular basis to research and development in support of this document.
THis includes especially the following NBD-PWG members:

\begin{itemize}
\tightlist
\item
  Gregor von\textbar{} Laszewski, Indiana University
\item
  Wo Chang, National Institute of Standard and Technology,
\item
  Fugang Wang, Indiana University
\item
  Geoffrey C. Fox, Indiana University
\item
  Alicia Zuniga-Alvarado, Consultant
\item
  Robert C. Whetsel, DISA/NBIS
\item
  Pratik Thakkar, Philips
\end{itemize}

Past contributors of earlier versions of this document include

\begin{itemize}
\tightlist
\item
  Badi Abdhul Wahid, formerly Indiana University
\end{itemize}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{table-of-contents}{%
\section{Table of Contents}\label{table-of-contents}}

\hypertarget{executive-summary}{%
\section{Executive Summary}\label{executive-summary}}

The \emph{NIST Big Data Interoperability Framework (NBDIF): Volume 8,
Reference Architecture Interfaces} document was prepared by the NIST Big
Data Public Working Group (NBD-PWG) Interface Subgroup to identify
interfaces in support of the NIST Big Data Reference Architecture
(NBDRA) The interfaces contain two different aspects:

\begin{itemize}
\item
  The definition of resources that are part of the NBDRA. These
  resources are formulated in JSON format and can be integrated into a
  REST framework or an object-based framework easily.
\item
  The definition of simple interface use cases that allow us to
  illustrate the usefulness of the resources defined.
\end{itemize}

The resources were categorized in groups that are identified by the
NBDRA set forward in the \emph{NBDIF: Volume 6, Reference Architecture}
document. While the \emph{NBDIF: Volume 3, Use Cases and General
Requirements} document provides \emph{application-}oriented high-level
use cases, the use cases defined in this document are subsets of them
and focus on \emph{interface} use cases. The interface use cases are not
meant to be complete examples, but showcase why the resource has been
defined. Hence, the interfaces use cases are only representative, and do
not represent the entire spectrum of Big Data usage. All the interfaces
were openly discussed in the working group. Additions are welcome and we
like to discuss your contributions in the group.

The NIST Big Data Interoperability Framework consists of nine volumes,
each of which addresses a specific key topic, resulting from the work of
the NBD-PWG. The nine volumes are:

\begin{itemize}
\tightlist
\item
  Volume 1: Definitions
\item
  Volume 2: Taxonomies
\item
  Volume 3: Use Cases and General Requirements
\item
  Volume 4: Security and Privacy
\item
  Volume 5: Architectures White Paper Survey
\item
  Volume 6: Reference Architecture
\item
  Volume 7: Standards Roadmap
\item
  Volume 8: Reference Architecture Interfaces
\item
  Volume 9: Adoption and Modernization
\end{itemize}

The NBDIF will be released in three versions, which correspond to the
three development stages of the NBD-PWG work. The three stages aim to
achieve the following with respect to the NBDRA.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify the high-level Big Data reference architecture key
  components, which are technology-, infrastructure-, and
  vendor-agnostic.
\item
  Define general interfaces between the NBDRA components.
\item
  Validate the NBDRA by building Big Data general applications through
  the general interfaces.
\end{enumerate}

This document is targeting Stage 2 of the NBDRA. Coordination of the
group is conducted on the NBD-PWG web page
(\url{https://bigdatawg.nist.gov}).

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\hypertarget{background}{%
\subsection{Background}\label{background}}

There is broad agreement among commercial, academic, and government
leaders about the remarkable potential of Big Data to spark innovation,
fuel commerce, and drive progress. Big Data is the common term used to
describe the deluge of data in today's networked, digitized,
sensor-laden, and information-driven world. The availability of vast
data resources carries the potential to answer questions previously out
of reach, including the following:

\begin{itemize}
\item
  How can a potential pandemic reliably be detected early enough to
  intervene?
\item
  Can new materials with advanced properties be predicted before these
  materials have ever been synthesized?
\item
  How can the current advantage of the attacker over the defender in
  guarding against cybersecurity threats be reversed?
\end{itemize}

There is also broad agreement on the ability of Big Data to overwhelm
traditional approaches. The growth rates for data volumes, speeds, and
complexity are outpacing scientific and technological advances in data
analytics, management, transport, and data user spheres.

Despite widespread agreement on the inherent opportunities and current
limitations of Big Data, a lack of consensus on some important
fundamental questions continues to confuse potential users and stymie
progress. These questions include the following:

\begin{itemize}
\tightlist
\item
  How is Big Data defined?
\item
  What attributes define Big Data solutions?
\item
  What is new in Big Data?
\item
  What is the difference between Big Data and \emph{bigger data} that
  has been collected for years?
\item
  How is Big Data different from traditional data environments and
  related applications?
\item
  What are the essential characteristics of Big Data environments?
\item
  How do these environments integrate with currently deployed
  architectures?
\item
  What are the central scientific, technological, and standardization
  challenges that need to be addressed to accelerate the deployment of
  robust, secure Big Data solutions?
\end{itemize}

Within this context, on March 29, 2012, the White House announced the
Big Data Research and Development Initiative (The White House Office of
Science and Technology Policy, ``Big Data is a Big Deal,'' \emph{OSTP
Blog}, accessed February 21, 2014,
\url{http://www.whitehouse.gov/blog/2012/03/29/big-data-big-deal}). The
initiative's goals include helping to accelerate the pace of discovery
in science and engineering, strengthening national security, and
transforming teaching and learning by improving analysts' ability to
extract knowledge and insights from large and complex collections of
digital data.

Six federal departments and their agencies announced more than \$200
million in commitments spread across more than 80 projects, which aim to
significantly improve the tools and techniques needed to access,
organize, and draw conclusions from huge volumes of digital data. The
initiative also challenged industry, research universities, and
nonprofits to join with the federal government to make the most of the
opportunities created by Big Data.

Motivated by the White House initiative and public suggestions, the
National Institute of Standards and Technology (NIST) accepted the
challenge to stimulate collaboration among industry professionals to
further the secure and effective adoption of Big Data. As a result of
NIST's Cloud and Big Data Forum held on January 15--17, 2013, there was
strong encouragement for NIST to create a public working group for the
development of a Big Data Standards Roadmap. Forum participants noted
that this roadmap should define and prioritize Big Data requirements,
including interoperability, portability, reusability, extensibility,
data usage, analytics, and technology infrastructure. In doing so, the
roadmap would accelerate the adoption of the most secure and effective
Big Data techniques and technology.

On June 19, 2013, the NIST Big Data Public Working Group (NBD-PWG) was
launched with extensive participation by industry, academia, and
government from across the nation. The scope of the NBD-PWG involves
forming a community of interests from all sectors---including industry,
academia, and government---with the goal of developing consensus on
definitions, taxonomies, secure reference architectures, security and
privacy, and, from these, a standards roadmap. Such a consensus would
create a vendor-neutral, technology- and infrastructure-independent
framework that would enable Big Data stakeholders to identify and use
the best analytics tools for their processing and visualization
requirements on the most suitable computing platform and cluster, while
also allowing added value from Big Data service providers.

The \emph{NIST Big Data Interoperability Framework} (NBDIF) will be
released in three versions, which correspond to the three stages of the
NBD-PWG work. The three stages aim to achieve the following with respect
to the NIST Big Data Reference Architecture (NBDRA).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify the high-level Big Data reference architecture key
  components, which are technology, infrastructure, and vendor agnostic.
\item
  Define general interfaces between the NBDRA components.
\item
  Validate the NBDRA by building Big Data general applications through
  the general interfaces.
\end{enumerate}

On September 16, 2015, seven NBDIF Version 1 volumes were published
(\url{http://bigdatawg.nist.gov/V1_output_docs.php}), each of which
addresses a specific key topic, resulting from the work of the NBD-PWG.
The seven volumes are as follows:

\begin{itemize}
\tightlist
\item
  Volume 1, Definitions
\item
  Volume 2, Taxonomies
\item
  Volume 3, Use Cases and General Requirements
\item
  Volume 4, Security and Privacy
\item
  Volume 5, Architectures White Paper Survey
\item
  Volume 6, Reference Architecture
\item
  Volume 7, Standards Roadmap
\end{itemize}

Currently, the NBD-PWG is working on Stage 2 with the goals to enhance
the Version 1 content, define general interfaces between the NBDRA
components by aggregating low-level interactions into high-level general
interfaces, and demonstrate how the NBDRA can be used. As a result of
the Stage 2 work, the following two additional NBDIF volumes have been
developed.

\begin{itemize}
\tightlist
\item
  Volume 8, Reference Architecture Interfaces
\item
  Volume 9, Adoption and Modernization
\end{itemize}

Version 2 of the NBDIF volumes, resulting from Stage 2 work, can be
downloaded from the NBD-PWG website
(\url{https://bigdatawg.nist.gov/V2_output_docs.php}). Potential areas
of future work for each volume during Stage 3 are highlighted in Section
\textbf{1.5}???????? of each volume. The current effort documented in
this volume reflects concepts developed within the rapidly evolving
field of Big Data.

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{Note}\NormalTok{ Section numbers}
\end{Highlighting}
\end{Shaded}

\hypertarget{scope-and-objectives-of-the-reference-architectures-subgroup}{%
\subsection{Scope and Objectives of the Reference Architectures
Subgroup}\label{scope-and-objectives-of-the-reference-architectures-subgroup}}

Reference architectures provide ``an authoritative source of information
about a specific subject area that guides and constrains the
instantiations of multiple architectures and solutions.'' Reference
architectures generally serve as a foundation for solution architectures
and may also be used for comparison and alignment of instantiations of
architectures and solutions.

The goal of the NBD-PWG Reference Architecture Subgroup is to develop an
open reference architecture for Big Data that achieves the following
objectives:

\begin{itemize}
\tightlist
\item
  Provides a common language for the various stakeholders;
\item
  Encourages adherence to common standards, specifications, and
  patterns;
\item
  Provides consistent methods for implementation of technology to solve
  similar problem sets;
\item
  Illustrates and improves understanding of the various Big Data
  components, processes, and systems, in the context of a vendor- and
  technology-agnostic Big Data conceptual model;
\item
  Provides a technical reference for U.S. government departments,
  agencies, and other consumers to understand, discuss, categorize, and
  compare Big Data solutions; and
\item
  Facilitates analysis of candidate standards for interoperability,
  portability, reusability, and extendibility.
\end{itemize}

The NBDRA is a high-level conceptual model crafted to serve as a tool to
facilitate open discussion of the requirements, design structures, and
operations inherent in Big Data. The NBDRA is intended to facilitate the
understanding of the operational intricacies in Big Data. It does not
represent the system architecture of a specific Big Data system, but
rather is a tool for describing, discussing, and developing
system-specific architectures using a common framework of reference. The
model is not tied to any specific vendor products, services, or
reference implementation, nor does it define prescriptive solutions that
inhibit innovation.

The NBDRA does not address the following:

\begin{itemize}
\tightlist
\item
  Detailed specifications for any organization's operational systems;
\item
  Detailed specifications of information exchanges or services; and
\item
  Recommendations or standards for integration of infrastructure
  products.
\end{itemize}

The goals of the Subgroup will be realized throughout the three planned
phases of the NBD-PWG work, as outlined in Section 1.1.

\hypertarget{report-production}{%
\subsection{Report Production}\label{report-production}}

The \emph{NBDIF: Volume 8,} \emph{References Architecture Interfaces} is
one of nine volumes, whose overall aims are to define and prioritize Big
Data requirements, including interoperability, portability, reusability,
extensibility, data usage, analytic techniques, and technology
infrastructure to support secure and effective adoption of Big Data. The
overall goals of this volume are to define and specify interfaces to
implement the Big Data Reference Architecture. This volume arose from
discussions during the weekly NBD-PWG conference calls. Topics included
in this volume began to take form in Phase 2 of the NBD-PWG work. This
volume represents the groundwork for additional content planned for
Phase 3. During the discussions, the NBD-PWG identified the need to
specify a variety of interfaces.

To enable interoperability between the NBDRA components, a list of
well-defined NBDRA interfaces is needed. These interfaces are documented
in this volume. To introduce them, the NBDRA structure will be followed,
focusing on interfaces that allow bootstrapping of the NBDRA. The
document begins with a summary of requirements that will be integrated
into our specifications. Subsequently, each section will introduce a
number of objects that build the core of the interface addressing a
specific aspect of the NBDRA. A selected number of \emph{interface use
cases} will be showcased to outline how the specific interface can be
used in a reference implementation of the NBDRA. Validation of this
approach can be achieved while applying it to the application use cases
that have been gathered in the \emph{NBDIF: Volume 3, Use Cases and
Requirements} document. These application use cases have considerably
contributed towards the design of the NBDRA. Hence the expectation is
that: (1) the interfaces can be used to help implement a Big Data
architecture for a specific use case; and (2) the proper implementation.
This approach can facilitate subsequent analysis and comparison of the
use cases.

This document is expected to grow with the help of contributions from
the community to achieve a comprehensive set of interfaces that will be
usable for the implementation of Big Data Architectures. To achieve
technical and high-quality document content, this document will go
through a public comment period along with NIST internal review.

\hypertarget{report-structure}{%
\subsection{Report Structure}\label{report-structure}}

The organization of this document roughly corresponds to the process
used by the NBD-PWG to develop the interfaces. Following the
introductory material presented in Section 1, the remainder of this
document is organized as follows:

\begin{itemize}
\tightlist
\item
  Section 2 presents the interface requirements;
\item
  Section 3 summarizes the elementary objects that are important to the
  NBDRA;
\item
  Section 4 presents several objects grouped by functional use; and
\item
  Four appendices provide supplementary information.
\end{itemize}

\hypertarget{future-work-on-this-volume}{%
\subsection{Future Work on this
Volume}\label{future-work-on-this-volume}}

A number of topics have not been discussed and clarified sufficiently to
be included in Version 2.2. Future topics will be identified during
discussions within the Reference Architecture Subgroup.

\hypertarget{nbdra-interface-requirements}{%
\section{NBDRA Interface
Requirements}\label{nbdra-interface-requirements}}

The development of a Big Data reference architecture requires a thorough
understanding of current techniques, issues, and concerns. To this end,
the NBD-PWG collected use cases to gain an understanding of current
applications of Big Data, conducted a survey of reference architectures
to understand commonalities within Big Data architectures in use,
developed a taxonomy to understand and organize the information
collected, and reviewed existing technologies and trends relevant to Big
Data. The results of these NBD-PWG activities were used in the
development of the NBDRA (Figure 1) and the interfaces presented herein.
Detailed descriptions of these activities can be found in the other
volumes of the \emph{NBDIF}.

\begin{figure}
\centering
\includegraphics{images/bdra.png}
\caption{\textbf{Figure 1:} NIST Big Data Reference Architecture
(NBDRA)}
\end{figure}

This vendor-neutral, technology- and infrastructure-agnostic conceptual
model, the NBDRA, is shown in Figure 1 and represents a Big Data system
composed of five logical functional components connected by
interoperability interfaces (i.e., services). Two fabrics envelop the
components, representing the interwoven nature of management and
security and privacy with all five of the components. These two fabrics
provide services and functionality to the five main roles in the areas
specific to Big Data and are crucial to any Big Data solution. Note:
None of the terminology or diagrams in these documents is intended to be
normative or to imply any business or deployment model. The terms
\emph{provider} and \emph{consumer} as used are descriptive of general
roles and are meant to be informative in nature.

The NBDRA is organized around five major roles and multiple sub-roles
aligned along two axes representing the two Big Data value chains: the
Information Value (horizontal axis) and the Information Technology (IT;
vertical axis). Along the Information Value axis, the value is created
by data collection, integration, analysis, and applying the results
following the value chain. Along the IT axis, the value is created by
providing networking, infrastructure, platforms, application tools, and
other IT services for hosting of and operating the Big Data in support
of required data applications. At the intersection of both axes is the
Big Data Application Provider role, indicating that data analytics and
its implementation provide the value to Big Data stakeholders in both
value chains. The term \emph{provider} as part of the Big Data
Application Provider and Big Data Framework Provider is there to
indicate that those roles provide or implement specific activities and
functions within the system. It does not designate a service model or
business entity.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{:}\ExtensionTok{warning}\NormalTok{: FIGURE 2 was at one point removed by somone, but the text was not updated}
\end{Highlighting}
\end{Shaded}

The DATA arrows in Figure 2 show the flow of data between the system's
main roles. Data flows between the roles either physically (i.e., by
value) or by providing its location and the means to access it (i.e., by
reference). The SW arrows show transfer of software tools for processing
of Big Data \emph{in situ}. The Service Use arrows represent software
programmable interfaces. While the main focus of the NBDRA is to
represent the run-time environment, all three types of communications or
transactions can happen in the configuration phase as well. Manual
agreements (e.g., service-level agreements) and human interactions that
may exist throughout the system are not shown in the NBDRA.

Detailed information on the NBDRA conceptual model is presented in the
\emph{NBDIF: Volume 6, Reference Architecture} document.

Prior to outlining the specific interfaces, general requirements are
introduced and the interfaces are defined.

\hypertarget{high-level-requirements-of-the-interface-approach}{%
\subsection{High-Level Requirements of the Interface
Approach}\label{high-level-requirements-of-the-interface-approach}}

This section focuses on the high-level requirements of the interface
approach that are needed to implement the reference architecture
depicted in Figure 1.

\hypertarget{technology--and-vendor-agnostic}{%
\subsubsection{Technology- and
Vendor-Agnostic}\label{technology--and-vendor-agnostic}}

Due to the many different tools, services, and infrastructures available
in the general area of Big Data, an interface ought to be as
vendor-independent as possible, while at the same time be able to
leverage best practices. Hence, a methodology is needed that allows
extension of interfaces to adapt and leverage existing approaches, but
also allows the interfaces to provide merit in easy specifications that
assist the formulation and definition of the NBDRA.

\hypertarget{support-of-plug-in-compute-infrastructure}{%
\subsubsection{Support of Plug-In Compute
Infrastructure}\label{support-of-plug-in-compute-infrastructure}}

As Big Data is not just about hosting data, but about analyzing data,
the interfaces provided herein must encapsulate a rich infrastructure
environment that is used by data scientists. This includes the ability
to integrate (or plug-in) various compute resources and services to
provide the necessary compute power to analyze the data. These resources
and services include the following:

-Access to hierarchy of compute resources from the laptop/desktop,
servers, data clusters, and clouds; -The ability to integrate
special-purpose hardware such as GPUs and FPGAs that are used in
accelerated analysis of data; and -The integration of services including
micro services that allow the analysis of the data by delegating them to
hosted or dynamically deployed services on the infrastructure of choice.

\hypertarget{orchestration-of-infrastructure-and-services}{%
\subsubsection{Orchestration of Infrastructure and
Services}\label{orchestration-of-infrastructure-and-services}}

From review of the use case collection, presented in the \emph{NBDIF:
Volume 3, Use Cases and General Requirements} document {[}4{]}, the need
arose to address the mechanism of preparing suitable infrastructures for
various use cases. As not every infrastructure is suited for every use
case, a custom infrastructure may be needed. As such, this document is
not attempting to deliver a single deployed NBDRA, but allow the setup
of an infrastructure that satisfies the particular use case. To achieve
this task, it is necessary to provision software stacks and services
while orchestrating their deployment and leveraging infrastructures. It
is not the focus of this document to replace existing orchestration
software and services, but provide an interface to them to leverage them
as part of defining and creating the infrastructure. Various
orchestration frameworks and services could therefore be leveraged, even
as part of the same framework, and work in orchestrated fashion to
achieve the goal of preparing an infrastructure suitable for one or more
applications.

\hypertarget{orchestration-of-big-data-applications-and-experiments}{%
\subsubsection{Orchestration of Big Data Applications and
Experiments}\label{orchestration-of-big-data-applications-and-experiments}}

The creation of the infrastructure suitable for Big Data applications
provides the basic computing environment. However, Big Data applications
may require the creation of sophisticated applications as part of
interactive experiments to analyze and probe the data. For this purpose,
the applications must be able to orchestrate and interact with
experiments conducted on the data while assuring reproducibility and
correctness of the data. For this purpose, a \emph{System Orchestrator}
(either the data scientists or a service acting on behalf of the data
scientist) is used as the command center to interact on behalf of the
Big Data Application Provider to orchestrate dataflow from Data
Provider, carry out the Big Data application life cycle with the help of
the Big Data Framework Provider, and enable the Data Consumer to consume
Big Data processing results. An interface is needed to describe these
interactions and to allow leveraging of experiment management frameworks
in scripted fashion. A customization of parameters is needed on several
levels. On the highest level, high--level, application-motivated
parameters are needed to drive the orchestration of the experiment. On
lower levels, these high-level parameters may drive and create
service-level agreements, augmented specifications, and parameters that
could even lead to the orchestration of infrastructure and services to
satisfy experiment needs.

\hypertarget{reusability}{%
\subsubsection{Reusability}\label{reusability}}

The interfaces provided must encourage reusability of the
infrastructure, services, and experiments described by them. This
includes (1) reusability of available analytics packages and services
for adoption; (2) deployment of customizable analytics tools and
services; and (3) operational adjustments that allow the services and
infrastructure to be adapted while at the same time allowing for
reproducible experiment execution.

\hypertarget{execution-workloads}{%
\subsubsection{Execution Workloads}\label{execution-workloads}}

One of the important aspects of distributed Big Data services can be
that the data served is simply too big to be moved to a different
location. Instead, an interface could allow the description and
packaging of analytics algorithms, and potentially also tools, as a
payload to a data service. This can be best achieved, not by sending the
detailed execution, but by sending an interface description that
describes how such an algorithm or tool can be created on the server and
be executed under security considerations (integrated with
authentication and authorization in mind).

\hypertarget{security-and-privacy-fabric-requirements}{%
\subsubsection{Security and Privacy Fabric
Requirements}\label{security-and-privacy-fabric-requirements}}

Although the focus of this document is not security and privacy, which
are documented in the \emph{NBDIF: Volume 4, Security and Privacy}
{[}8{]}, the interfaces defined herein must be capable of integration
into a secure reference architecture that supports secure execution,
secure data transfer, and privacy. Consequently, the interfaces defined
herein can be augmented with frameworks and solutions that provide such
mechanisms. Thus, diverse requirement needs stemming from different use
cases addressing security need to be distinguished. To contrast that the
security requirements between applications can vary drastically, the
following example is provided. Although many of the interfaces and their
objects to support Big Data applications in physics are similar to those
in healthcare, they differ in the integration of security interfaces and
policies. While in physics the protection of data is less of an issue,
it is a stringent requirement in healthcare. Thus, deriving
architectural frameworks for both may use largely similar components,
but addressing security issues will be very different. In future
versions of this document, the security of interfaces may be addressed.
In the meanwhile, they are considered an advanced use case showcasing
that the validity of the specifications introduced here is preserved,
even if security and privacy requirements differ vastly among
application use cases.

\hypertarget{component-specific-interface-requirements}{%
\subsection{Component-Specific Interface
Requirements}\label{component-specific-interface-requirements}}

This section summarizes the requirements for the interfaces of the NBDRA
components. The five components are listed in Figure 1 and addressed in
each of the subsections as part of Section 2.2.1 (System Orchestrator
Interface Requirements) and Section 2.2.6 (Big Data Application Provider
to Big Data Framework Provider Interface) of this document. The five
main functional components of the NBDRA represent the different
technical roles within a Big Data system. The functional components are
listed below and discussed in subsequent subsections.

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{NOTE}\NormalTok{: SECTION NUMBERS}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  System Orchestrator: Defines and integrates the required data
  application activities into an operational vertical system (see
  Section 2.2.1);
\item
  Data Provider: Introduces new data or information feeds into the Big
  Data system (see Section 2.2.2);
\item
  Data Consumer: Includes end users or other systems that use the
  results of the Big Data Application Provider (see Section 2.2.3);
\item
  Big Data Application Provider: Executes a data life cycle to meet
  security and privacy requirements as well as System
  Orchestrator-defined requirements (see Section 2.2.4);
\item
  Big Data Framework Provider: Establishes a computing framework in
  which to execute certain transformation applications while protecting
  the privacy and integrity of data (see Section 2.2.5); and
\item
  Big Data Application Provider to Framework Provider Interface: Defines
  an interface between the application specification and the provider
  (see Section 2.2.4).
\end{itemize}

\hypertarget{system-orchestrator-interface-requirements}{%
\subsubsection{System Orchestrator Interface
Requirements}\label{system-orchestrator-interface-requirements}}

The System Orchestrator role includes defining and integrating the
required data application activities into an operational vertical
system. Typically, the System Orchestrator involves a collection of more
specific roles, performed by one or more actors, which manage and
orchestrate the operation of the Big Data system. These actors may be
human components, software components, or some combination of the two.
The function of the System Orchestrator is to configure and manage the
other components of the Big Data architecture to implement one or more
workloads that the architecture is designed to execute. The workloads
managed by the System Orchestrator may be assigning/provisioning
framework components to individual physical or virtual nodes at the
lower level, or providing a graphical user interface that supports the
specification of workflows linking together multiple applications and
components at the higher level. The System Orchestrator may also,
through the Management Fabric, monitor the workloads and system to
confirm that specific quality of service requirements is met for each
workload, and may elastically assign and provision additional physical
or virtual resources to meet workload requirements resulting from
changes/surges in the data or number of users/transactions. The
interface to the System Orchestrator must be capable of specifying the
task of orchestration the deployment, configuration, and the execution
of applications within the NBDRA. A simple vendor-neutral specification
to coordinate the various parts either as simple parallel language tasks
or as a workflow specification is needed to facilitate the overall
coordination. Integration of existing tools and services into the System
Orchestrator as extensible interfaces is desirable.

\hypertarget{data-provider-interface-requirements}{%
\subsubsection{Data Provider Interface
Requirements}\label{data-provider-interface-requirements}}

The Data Provider role introduces new data or information feeds into the
Big Data system for discovery, access, and transformation by the Big
Data system. New data feeds are distinct from the data already in use by
the system and residing in the various system repositories. Similar
technologies can be used to access both new data feeds and existing
data. The Data Provider actors can be anything from a sensor, to a human
inputting data manually, to another Big Data system. Interfaces for data
providers must be able to specify a data provider so it can be located
by a data consumer. It also must include enough details to identify the
services offered so they can be pragmatically reused by consumers.
Interfaces to describe pipes and filters must be addressed.

\hypertarget{data-consumer-interface-requirements}{%
\subsubsection{Data Consumer Interface
Requirements}\label{data-consumer-interface-requirements}}

Like the Data Provider, the role of Data Consumer within the NBDRA can
be an actual end user or another system. In many ways, this role is the
mirror image of the Data Provider, with the entire Big Data framework
appearing like a Data Provider to the Data Consumer. The activities
associated with the Data Consumer role include the following:

\begin{itemize}
\tightlist
\item
  Search and Retrieve,
\item
  Download,
\item
  Analyze Locally,
\item
  Reporting,
\item
  Visualization, and
\item
  Data to Use for Their Own Processes.
\end{itemize}

The interface for the data consumer must be able to describe the
consuming services and how they retrieve information or leverage data
consumers.

\hypertarget{big-data-application-interface-provider-requirements}{%
\subsubsection{Big Data Application Interface Provider
Requirements}\label{big-data-application-interface-provider-requirements}}

The Big Data Application Provider role executes a specific set of
operations along the data life cycle to meet the requirements
established by the System Orchestrator, as well as meeting security and
privacy requirements. The Big Data Application Provider is the
architecture component that encapsulates the business logic and
functionality to be executed by the architecture. The interfaces to
describe Big Data applications include interfaces for the various
subcomponents including collections, preparation/curation, analytics,
visualization, and access. Some of the interfaces used in these
subcomponents can be reused from other interfaces, which are introduced
in other sections of this document. Where appropriate,
application-specific interfaces will be identified and examples provided
with a focus on use cases as identified in the \emph{NBDIF: Volume 3,
Use Cases and General Requirements}.

\hypertarget{collection}{%
\paragraph{Collection}\label{collection}}

In general, the collection activity of the Big Data Application Provider
handles the interface with the Data Provider. This may be a general
service, such as a file server or web server configured by the System
Orchestrator to accept or perform specific collections of data, or it
may be an application-specific service designed to pull data or receive
pushes of data from the Data Provider. Since this activity is receiving
data at a minimum, it must store/buffer the received data until it is
persisted through the Big Data Framework Provider. This persistence need
not be to physical media but may simply be to an in-memory queue or
other service provided by the processing frameworks of the Big Data
Framework Provider. The collection activity is likely where the
extraction portion of the Extract, Transform, Load (ETL)/Extract, Load,
Transform (ELT) cycle is performed. At the initial collection stage,
sets of data (e.g., data records) of similar structure are collected
(and combined), resulting in uniform security, policy, and other
considerations. Initial metadata is created (e.g., subjects with keys
are identified) to facilitate subsequent aggregation or look-up methods.

\hypertarget{preparation}{%
\paragraph{Preparation}\label{preparation}}

The preparation activity is where the transformation portion of the
ETL/ELT cycle is likely performed, although analytics activity will also
likely perform advanced parts of the transformation. Tasks performed by
this activity could include data validation (e.g., checksums/hashes,
format checks), cleansing (e.g., eliminating bad records/fields),
outlier removal, standardization, reformatting, or encapsulating. This
activity is also where source data will frequently be persisted to
archive storage in the Big Data Framework Provider and provenance data
will be verified or attached/associated. Verification or attachment may
include optimization of data through manipulations (e.g., deduplication)
and indexing to optimize the analytics process. This activity may also
aggregate data from different Data Providers, leveraging metadata keys
to create an expanded and enhanced data set.

\hypertarget{analytics}{%
\paragraph{Analytics}\label{analytics}}

The analytics activity of the Big Data Application Provider includes the
encoding of the low-level business logic of the Big Data system (with
higher-level business process logic being encoded by the System
Orchestrator). The activity implements the techniques to extract
knowledge from the data based on the requirements of the vertical
application. The requirements specify the data processing algorithms to
produce new insights that will address the technical goal. The analytics
activity will leverage the processing frameworks to implement the
associated logic. This typically involves the activity providing
software that implements the analytic logic to the batch and/or
streaming elements of the processing framework for execution. The
messaging/communication framework of the Big Data Framework Provider may
be used to pass data or control functions to the application logic
running in the processing frameworks. The analytic logic may be broken
up into multiple modules to be executed by the processing frameworks
which communicate, through the messaging/communication framework, with
each other and other functions instantiated by the Big Data Application
Provider.

\hypertarget{visualization}{%
\paragraph{Visualization}\label{visualization}}

The visualization activity of the Big Data Application Provider prepares
elements of the processed data and the output of the analytic activity
for presentation to the Data Consumer. The objective of this activity is
to format and present data in such a way as to optimally communicate
meaning and knowledge. The visualization preparation may involve
producing a text-based report or rendering the analytic results as some
form of graphic. The resulting output may be a static visualization and
may simply be stored through the Big Data Framework Provider for later
access. However, the visualization activity frequently interacts with
the access activity, the analytics activity, and the Big Data Framework
Provider (processing and platform) to provide interactive visualization
of the data to the Data Consumer based on parameters provided to the
access activity by the Data Consumer. The visualization activity may be
completely application-implemented, leverage one or more application
libraries, or may use specialized visualization processing frameworks
within the Big Data Framework Provider.

\hypertarget{access}{%
\paragraph{Access}\label{access}}

The access activity within the Big Data Application Provider is focused
on the communication/interaction with the Data Consumer. Like the
collection activity, the access activity may be a generic service such
as a web server or application server that is configured by the System
Orchestrator to handle specific requests from the Data Consumer. This
activity would interface with the visualization and analytic activities
to respond to requests from the Data Consumer (who may be a person) and
uses the processing and platform frameworks to retrieve data to respond
to Data Consumer requests. In addition, the access activity confirms
that descriptive and administrative metadata and metadata schemes are
captured and maintained for access by the Data Consumer and as data is
transferred to the Data Consumer. The interface with the Data Consumer
may be synchronous or asynchronous in nature and may use a pull or push
paradigm for data transfer.

\hypertarget{big-data-provider-framework-interface-requirements}{%
\subsubsection{Big Data Provider Framework Interface
Requirements}\label{big-data-provider-framework-interface-requirements}}

Data for Big Data applications are delivered through data providers.
They can be either local providers, data contributed by a user, or
distributed data providers, data on the Internet. This interface must be
able to provide the following functionality:

\begin{itemize}
\tightlist
\item
  Interfaces to files,
\item
  Interfaces to virtual data directories,
\item
  Interfaces to data streams, and
\item
  Interfaces to data filters.
\end{itemize}

\hypertarget{infrastructures-interface-requirements}{%
\paragraph{Infrastructures Interface
Requirements}\label{infrastructures-interface-requirements}}

This Big Data Framework Provider element provides all the resources
necessary to host/run the activities of the other components of the Big
Data system. Typically, these resources consist of some combination of
physical resources, which may host/support similar virtual resources.
The NBDRA needs interfaces that can be used to deal with the underlying
infrastructure to address networking, computing, and storage.

\hypertarget{platforms-interface-requirements}{%
\paragraph{Platforms Interface
Requirements}\label{platforms-interface-requirements}}

As part of the NBDRA platforms, interfaces are needed that can address
platform needs and services for data organization, data distribution,
indexed storage, and file systems.

\hypertarget{processing-interface-requirements}{%
\paragraph{Processing Interface
Requirements}\label{processing-interface-requirements}}

The processing frameworks for Big Data provide the necessary
infrastructure software to support implementation of applications that
can deal with the volume, velocity, variety, and variability of data.
Processing frameworks define how the computation and processing of the
data is organized. Big Data applications rely on various platforms and
technologies to meet the challenges of scalable data analytics and
operation. A requirement is the ability to interface easily with
computing services that offer specific analytics services, batch
processing capabilities, interactive analysis, and data streaming.

\hypertarget{crosscutting-interface-requirements}{%
\paragraph{Crosscutting Interface
Requirements}\label{crosscutting-interface-requirements}}

Several crosscutting interface requirements within the Big Data
Framework Provider include messaging, communication, and resource
management. Often these services may be hidden from explicit interface
use as they are part of larger systems that expose higher-level
functionality through their interfaces. However, such interfaces may
also be exposed on a lower level in case finer-grained control is
needed. The need for such crosscutting interface requirements will be
extracted from the \emph{NBDIF: Volume 3, Use Cases and General
Requirements} document.

\hypertarget{messagingcommunications-frameworks}{%
\paragraph{Messaging/Communications
Frameworks}\label{messagingcommunications-frameworks}}

Messaging and communications frameworks have their roots in the High
Performance Computing environments long popular in the scientific and
research communities. Messaging/Communications Frameworks were developed
to provide application programming interfaces (APIs) for the reliable
queuing, transmission, and receipt of data.

\hypertarget{resource-management-framework}{%
\paragraph{Resource Management
Framework}\label{resource-management-framework}}

As Big Data systems have evolved and become more complex, and as
businesses work to leverage limited computation and storage resources to
address a broader range of applications and business challenges, the
requirement to effectively manage those resources has grown
significantly. While tools for resource management and \emph{elastic
computing} have expanded and matured in response to the needs of cloud
providers and virtualization technologies, Big Data introduces unique
requirements for these tools. However, Big Data frameworks tend to fall
more into a distributed computing paradigm, which presents additional
challenges.

\hypertarget{big-data-application-provider-to-big-data-framework-provider-interface}{%
\subsubsection{Big Data Application Provider to Big Data Framework
Provider
Interface}\label{big-data-application-provider-to-big-data-framework-provider-interface}}

The Big Data Framework Provider typically consists of one or more
hierarchically organized instances of the components in the NBDRA IT
value chain (Figure 1). There is no requirement that all instances at a
given level in the hierarchy be of the same technology. In fact, most
Big Data implementations are hybrids that combine multiple technology
approaches to provide flexibility or meet the complete range of
requirements, which are driven from the Big Data Application Provider.

\hypertarget{specification-paradigm}{%
\section{Specification Paradigm}\label{specification-paradigm}}

This section summarizes the elementary services that are important to
the NBDRA.

\hypertarget{hybrid-and-multiple-frameworks}{%
\subsection{Hybrid and Multiple
Frameworks}\label{hybrid-and-multiple-frameworks}}

To avoid vendor lock-in, Big Data systems must be able to deal with
hybrid and multiple frameworks. This is not only true for Clouds,
containers, DevOps, but also for components of the NBDRA.

\hypertarget{design-by-research-oriented-architecture}{%
\subsection{Design by Research Oriented
Architecture}\label{design-by-research-oriented-architecture}}

A resource-oriented architecture represents a software architecture and
programming paradigm for designing and developing software in the form
of resources. It is often associated with \emph{REST} interfaces. The
resources are software components which can be reused in concrete
reference implementations. The srevice speccification is conducted with
OpenAPI, allowing use to provide it in a very general form that is
indepndent of the froamework or computer langusge in which the services
can be specified. Note that OpenAPI defines services in REpresentational
State Transfer (REST) The brevious verion only specified the resource
objects.

\hypertarget{design-by-example}{%
\subsection{Design by Example}\label{design-by-example}}

To accelerate discussion among the NBD-PWG members, we encourage
contributors to this documemt to also provide us with examples that we
can include in an appendix.

\hypertarget{version-management}{%
\subsection{Version Management}\label{version-management}}

During the design phase and inbetween versions of this document
enhancemnents are managed through GitHub and community contributions are
managed via GitHub issues. This allows us to preserve the history of
this document. When a new version is ready, we will tagg the version in
GitHub. Older version will through this process also be available as
historical documents. Discussions about objects in written form are
communicated as GitHub issues.

\hypertarget{interface-compliancy}{%
\subsection{Interface Compliancy}\label{interface-compliancy}}

Due to the easy extensibility of the objects in this document and their
implicit interfaces, it is important to introduce a terminology that
allows the definition of interface compliancy. We define three levels of
interface compliance as follows:

\begin{itemize}
\item
  \textbf{Full Compliance:} These are reference implementations that
  provide full compliance to the objects defined in this document. A
  version number will be added to assure that the snapshot in time of
  the objects is associated with the version. This reference
  implementation will implement all objects.
\item
  \textbf{Partial Compliance:} These are reference implementations that
  provide partial compliance to the objects defined in this document. A
  version number will be added to assure that the snapshot in time of
  the objects is associated with the version. This reference
  implementation will implement a partial list of the objects. A
  document will be generated during the reference implementation that
  lists all objects defined, but also lists the objects that are not
  defined by the reference architecture. The document will outline which
  objects and interfaces have been implemented.
\item
  \textbf{Full and Extended Compliance:} These are interfaces that in
  addition to the full compliance also introduce additional interfaces
  and extend them. A document will be generated during the reference
  implementation that lists the differences to the document defined
  here.
\end{itemize}

The documents generated during the reference implementation can then be
forwarded to the Reference Architecture Subgroup for further discussion
and for possible future modifications based on additional practical user
feedback.

\hypertarget{specification}{%
\section{Specification}\label{specification}}

We will provide the specifications to this document through an automated
document crearion process so that the actual OpenAPI specifications are
the source for the document. Thus we will have all OpenAPI
specifications located in the following directory in GitHub:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{Addd}\NormalTok{ the link to the GitHub dir}
\end{Highlighting}
\end{Shaded}

Limitations of the current implementation are as follows. It is a
demonstration that showcases the generation of a fully functioning REST
service based on the specifications provided in this document. However,
it is expected that scalability, distribution of services, and other
advanced options need to be addressed based on application requirements.

\hypertarget{list-of-specifications}{%
\subsection{List of specifications}\label{list-of-specifications}}

The following table lists the current set of resource objects that we
are defining in this draft. Additional objects are alos available at

\begin{itemize}
\tightlist
\item
  \url{https://github.com/cloudmesh-community/nist/tree/master/services}
\end{itemize}

\hypertarget{identity}{%
\subsection{Identity}\label{identity}}

As part of services we often need to specify an identity. In addition
such persons are often part of groups and have roles within these
groups. Thus we distinguis three important terms related to the
identity:

\begin{itemize}
\tightlist
\item
  Profile - The information identifying the profile of a person
\item
  Group - A group that a person may belong to that is important to
  define access to services
\item
  Role - A role given to a person as part of the group that can refine
  access rights.
\item
  Organization - The information representing an Organization that
  manages a Big Data Service
\end{itemize}

\hypertarget{authentication}{%
\subsubsection{Authentication}\label{authentication}}

At this time we have not yet included the mechanims on how to manage
authentication to external services such as clouds that can stage
virtual machines. However in cloudmesh we have shown multiple solutions
to this

\begin{itemize}
\tightlist
\item
  Local configuration file: A configuration file is managed locally to
  allow access to the clouds. It is in the designers responsibility npot
  to expose such credentials
\item
  Session based authentication. No passwords are stored in teh
  configuration file and access is granted on a per session basis wher
  ethe password neds to be entered
\item
  Service based authentication. The authentication is delegated to an
  external process. One example here is alos oAuth.
\item
  The serive that acts in behalf of the user needs to have access to the
  appropriate cloud provider credentials
\end{itemize}

An example for a configuration file is provided at

\begin{itemize}
\tightlist
\item
  \url{https://github.com/cloudmesh-community/cm/blob/master/cm4/etc/cloudmesh4.yaml}
\end{itemize}

\hypertarget{profile}{%
\subsubsection{Profile}\label{profile}}

Profiles are used to store information about users. User information can
be reused in other services. THis is useful to create virtual
organization the depend on user data. Profiles can be added, removed and
listed. A group in the profile can be used to augment users to be part
of one or more groups. A number of roles can specify a specific role of
a user.

Terminology

Group: A Person with profile can be part of a Group

Role: A person with profile can have a role within that Group

\hypertarget{properties-profile}{%
\paragraph{Properties Profile}\label{properties-profile}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
uuid & string & A unique id for the profile\tabularnewline
username & string & The username associated with the
profile\tabularnewline
group & array{[}string{]} & A list of groups that are associated to the
profile\tabularnewline
role & array{[}string{]} & A list of groups that are associated to the
profile\tabularnewline
resource & string & A resource this profile may belong to\tabularnewline
context & string & The context the profile may belong to\tabularnewline
description & string & A description for this profile\tabularnewline
firstname & string & The firstanme of the profile user\tabularnewline
lastname & string & The lastname of the profile user\tabularnewline
publickey & string & The lastname of the profile user\tabularnewline
email & string & The email of the profile user\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths}{%
\paragraph{Paths}\label{paths}}

\hypertarget{cloudmeshprofileprofile}{%
\subparagraph{/cloudmesh/profile/profile}\label{cloudmeshprofileprofile}}

GET /cloudmesh/profile/profile

Returns all profiles

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & profile information &
\protect\hyperlink{profile}{Profile}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/profile/profile

Create a new profile

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
profile & body & The new profile to create & False &
\protect\hyperlink{profile}{Profile}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshprofileprofileuuid}{%
\subparagraph{/cloudmesh/profile/profile/\{uuid\}}\label{cloudmeshprofileprofileuuid}}

GET /cloudmesh/profile/profile/\{uuid\}

Returns the profile of a user while looking it up with the UUID

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & profile information &
\protect\hyperlink{profile}{Profile}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
uuid & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{profile.yaml}{%
\paragraph{profile.yaml}\label{profile.yaml}}

\begin{verbatim}
---
swagger: "2.0"
info:
  version: 3.0.3
  date: 11-06-2018
  title: "Profile"
  description: |-
  
    Profiles are used to store information about users. User
    information can be reused in other services. THis is useful to
    create virtual organization the depend on user data.  Profiles can
    be added, removed and listed. A group in the profile can be used
    to augment users to be part of one or more groups.  A number of
    roles can specify a specific role of a user.

    Terminology

    Group: A Person with profile can be part of a Group

    Role: A person with profile can have a role within that Group

  termsOfService: 'https://github.com/cloudmesh-community/nist/blob/master/LICENSE.txt'
  contact:
    name: "Cloudmesh Profile"
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: "Apache"
host: "localhost:8080"
schemes:
  - "http"
consumes:
  - "application/json"
produces:
  - "application/json"
paths:
  /cloudmesh/profile/profile:
    get:
      tags:
        - "profile"
      description: "Returns all profiles"
      operationId: get_profile
      produces:
        - "application/json"
      responses:
        "200":
          description: "profile information"
          schema:
            $ref: "#/definitions/Profile"
    put:
      tags:
        - "profile"
      summary: "Create a new profile"
      description: "Create a new profile"      
      operationId: add_profile
      parameters:
        - in: body
          name: profile
          description: "The new profile to create"
          schema:
            $ref: "#/definitions/Profile"
      responses:
        "201":
          description: Created
  /cloudmesh/profile/profile/{uuid}:
    get:
      tags:
        - "profile"
      description: "Returns the profile of a user while looking it up with the UUID"
      operationId: getProfileByUuid
      parameters:
        - name: uuid
          in: path
          required: true
          type: string
      produces:
        - "application/json"
      responses:
        "200":
          description: "profile information"
          schema:
            $ref: "#/definitions/Profile"
definitions:
  Profile:
    type: "object"
    properties:
      uuid:
        type: "string"
        description: A unique id for the profile
      username:
        type: "string"
        description: The username associated with the profile
      group:
        type: array
        description: A list of groups that are associated to the profile
        items:
          type: "string"
      role:
        type: array
        description: A list of groups that are associated to the profile
        items:
          type: "string"
      resource:
        type: "string"
        description: A resource this profile may belong to
      context:
        type: "string"
        description: The context the profile may belong to
      description:
        type: "string"
        description: A description for this profile
      firstname:
        type: "string"
        description: The firstanme of the profile user
      lastname:
        type: "string"
        description: The lastname of the profile user
      publickey:
        type: "string"
        description: The lastname of the profile user
      email:
        type: "string"
        description: The email of the profile user
\end{verbatim}

\hypertarget{organization}{%
\subsubsection{Organization}\label{organization}}

An important concept in many applications is the management of a group
of users in an organization that manages a Big Data application or
infrastructure. User group management can be achieved through three
concepts. First, it can be achieved by using the profile and user
resources itself as they contain the ability to manage multiple users as
part of the REST interface. The second concept is to create a (virtual)
organization that lists all users within the virtual organization. The
third concept is to introduce groups and roles either as part of the
user definition or as part of a simple list similar to the organization.

\hypertarget{properties-organization}{%
\paragraph{Properties Organization}\label{properties-organization}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & Name of the organization\tabularnewline
users & array & list of users\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-1}{%
\paragraph{Paths}\label{paths-1}}

\hypertarget{cloudmeshorganization}{%
\subparagraph{/cloudmesh/organization}\label{cloudmeshorganization}}

GET /cloudmesh/organization

Returns all users of the organization

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & organization info &
\protect\hyperlink{organization}{Organization}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/organization

Create a new organization

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
organization & body & The new organization to create & False &
\protect\hyperlink{organization}{Organization}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshorganizationname}{%
\subparagraph{/cloudmesh/organization/\{name\}}\label{cloudmeshorganizationname}}

GET /cloudmesh/organization/\{name\}

Returns the organization

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & organization info &
\protect\hyperlink{organization}{Organization}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & The name of the organization & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{organization.yaml}{%
\paragraph{organization.yaml}\label{organization.yaml}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.3
  title: organization
  description: |-
  
    An important concept in many applications is the management of a
    group of users in an organization that manages a Big Data
    application or infrastructure. User group management can be
    achieved through three concepts. First, it can be achieved by
    using the profile and user resources itself as they contain the
    ability to manage multiple users as part of the REST
    interface. The second concept is to create a (virtual)
    organization that lists all users within the virtual
    organization. The third concept is to introduce groups and roles
    either as part of the user definition or as part of a simple list
    similar to the organization.

  termsOfService: 'https://github.com/cloudmesh-community/nist/blob/master/LICENSE.txt'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/organization:
    get:
      description: Returns all users of the organization
      operationId: get_organization
      produces:
        - application/json
      responses:
        '200':
          description: organization info
          schema:
            $ref: '#/definitions/Organization'
    put:
      summary: Create a new organization
      description: Create a new organization
      operationId: add_organization
      parameters:
        - in: body
          name: organization
          description: The new organization to create
          schema:
            $ref: '#/definitions/Organization'
      responses:
        '201':
          description: Created
  '/cloudmesh/organization/{name}':
    get:
      summary: Returns the organization 
      description: Returns the organization
      operationId: get_organization_by_name
      parameters:
        - name: name
          description: The name of the organization
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: organization info
          schema:
            $ref: '#/definitions/Organization'
definitions:
  Organization:
    type: object
    properties:
      name:
        description: Name of the organization
        type: string
      users:
        description: list of users
        type: array
        items: ../users/user.yaml#/definitions/Users


\end{verbatim}

\hypertarget{keystore}{%
\subsubsection{Keystore}\label{keystore}}

A service to store key, value, type information. All of them are stored
as Strings.

\hypertarget{properties-key}{%
\paragraph{Properties Key}\label{properties-key}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
uuid & string & The uuid of the key, tha uuid must be
unique\tabularnewline
name & string & The name to access the key. The name must be
unique\tabularnewline
description & string & A description of the key\tabularnewline
value & string & The string representing the key\tabularnewline
kind & string & The type of the key\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-2}{%
\paragraph{Paths}\label{paths-2}}

\hypertarget{cloudmeshkeystorekey}{%
\subparagraph{/cloudmesh/keystore/key}\label{cloudmeshkeystorekey}}

GET /cloudmesh/keystore/key

Returns all keys

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & key info & \protect\hyperlink{key}{Key}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/keystore/key

Create a new key

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
key & body & The new key to create & False &
\protect\hyperlink{key}{Key}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshkeystorekeyname}{%
\subparagraph{/cloudmesh/keystore/key/\{name\}}\label{cloudmeshkeystorekeyname}}

GET /cloudmesh/keystore/key/\{name\}

Returns the key by name

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & key info & \protect\hyperlink{key}{Key}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{keystore.yaml}{%
\paragraph{keystore.yaml}\label{keystore.yaml}}

\begin{verbatim}
---
swagger: '2.0'
info:
  version: 3.0.3
  date: 11-06-2018
  title: key
  description: |-
  
    A service to store key, value, type information. All of them are
    stored as Strings.

  termsOfService: 'https://github.com/cloudmesh-community/nist/blob/master/LICENSE.txt'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/keystore/key:
    get:
      tags:
        - "keystore"
      description: Returns all keys
      operationId: get_key
      produces:
        - application/json
      responses:
        '200':
          description: key info
          schema:
            $ref: '#/definitions/Key'
    put:
      tags:
        - "keystore"
      summary: Create a new key
      description: Create a new key      
      operationId: add_key
      parameters:
        - in: body
          name: key
          description: The new key to create
          schema:
            $ref: '#/definitions/Key'
      responses:
        '201':
          description: Created
  /cloudmesh/keystore/key/{name}:
    get:
      tags:
        - "keystore"
      description: Returns the key by name
      operationId: get_key_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: key info
          schema:
            $ref: '#/definitions/Key'
definitions:
  Key:
    type: object
    properties:
      uuid:
        type: string
        description: The uuid of the key, tha uuid must be unique
      name:
        type: string
        description: The name to access the key. The name must be unique
      description: 
        type: string
        description: A description of the key
      value:
        type: string
        description: The string representing the key        
      kind:
        type: string
        description: The type of the key        
\end{verbatim}

\hypertarget{general-resources}{%
\subsection{General Resources}\label{general-resources}}

\hypertarget{timestamp}{%
\subsubsection{Timestamp}\label{timestamp}}

Often data needs to be timestamped to indicate when it has been
accessed, created, or modified. All objects defined in this document
will have, in their final version, a timestamp.

\begin{itemize}
\tightlist
\item
  TODO: assign and review, we do not need a service for this but some
  mechanism so each resource has timestamps
\end{itemize}

\hypertarget{properties-timestamp}{%
\paragraph{Properties Timestamp}\label{properties-timestamp}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
accessed & date & ERROR: description missing\tabularnewline
created & date & ERROR: description missing\tabularnewline
modified & date & ERROR: description missing\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-3}{%
\paragraph{Paths}\label{paths-3}}

\hypertarget{cloudmeshtimestamps}{%
\subparagraph{/cloudmesh/timestamps}\label{cloudmeshtimestamps}}

GET /cloudmesh/timestamps

Returns all timestamps

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & timestamp info &
\protect\hyperlink{timestamp}{Timestamp}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/timestamps

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
timestamp & body & The new timestamp to create & False &
\protect\hyperlink{timestamp}{Timestamp}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshtimestampname}{%
\subparagraph{/cloudmesh/timestamp/\{name\}}\label{cloudmeshtimestampname}}

GET /cloudmesh/timestamp/\{name\}

Returns a timestamp

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & timestamp info &
\protect\hyperlink{timestamp}{Timestamp}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{timestamp.yaml}{%
\paragraph{timestamp.yaml}\label{timestamp.yaml}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.2
  date: 10-30-2018
  title: timestamp
  description: |-
  
    Often data needs to be timestamped to indicate when it has been
    accessed, created, or modified. All objects defined in this
    document will have, in their final version, a timestamp.

    * TODO: assign and review, we do not need a service for this
      but some mechanism so each resource has timestamps

  termsOfService: 'https://github.com/cloudmesh-community/nist/blob/master/LICENSE.txt'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/timestamps:
    get:
      description: Returns all timestamps
      operationId: get_timestamp
      produces:
        - application/json
      responses:
        '200':
          description: timestamp info
          schema:
            $ref: '#/definitions/Timestamp'
    put:
      summary: Create a new timestamp
      operationId: add_timestamp
      parameters:
        - in: body
          name: timestamp
          description: The new timestamp to create
          schema:
            $ref: '#/definitions/Timestamp'
      responses:
        '201':
          description: Created
  '/cloudmesh/timestamp/{name}':
    get:
      description: Returns a timestamp
      operationId: get_timestamp_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: timestamp info
          schema:
            $ref: '#/definitions/Timestamp'
definitions:
  Timestamp:
    type: object
    description: the timestamp
    properties:
      accessed:
        type: date
      created:
        type: date
      modified:
        type: date

\end{verbatim}

\hypertarget{alias}{%
\subsubsection{Alias}\label{alias}}

A user may be interested to create an alias for a resource. This is a
name useful to the user. Users can deploy an alias server in which they
store such aliasses for resources. Such aliasses could naturally be
shared with othere. A resource could have one or more aliasses. The
reason for an alias is that a resource may have a complex name but a
user may want to refer to the resource using a name that is suitable for
the user's application.

\hypertarget{properties-alias}{%
\paragraph{Properties Alias}\label{properties-alias}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & The name of the alias\tabularnewline
origin & string & The original object name\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-4}{%
\paragraph{Paths}\label{paths-4}}

\hypertarget{cloudmeshalias}{%
\subparagraph{/cloudmesh/alias}\label{cloudmeshalias}}

GET /cloudmesh/alias

Returns all aliases

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & alias information &
\protect\hyperlink{alias}{Alias}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/alias

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
alias & body & The new alias to create & False &
\protect\hyperlink{alias}{Alias}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshaliasname}{%
\subparagraph{/cloudmesh/alias/\{name\}}\label{cloudmeshaliasname}}

GET /cloudmesh/alias/\{name\}

Returns an alias

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & alias info & \protect\hyperlink{alias}{Alias}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{alias.yaml}{%
\paragraph{alias.yaml}\label{alias.yaml}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.2
  date: 10-30-2018
  title: alias
  description: |-

    A user may be interested to create an alias for a resource. This
    is a name useful to the user. Users can deploy an alias server in
    which they store such aliasses for resources. Such aliasses could
    naturally be shared with othere. A resource could have one or more
    aliasses.  The reason for an alias is that a resource may have a
    complex name but a user may want to refer to the resource using a
    name that is suitable for the user's application.

  termsOfService: 'http://bin.io/terms/'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/alias:
    get:
      description: Returns all aliases
      operationId: get_alias
      produces:
        - application/json
      responses:
        '200':
          description: alias information
          schema:
            $ref: '#/definitions/Alias'
    put:
      summary: Create a new alias
      operationId: add_alias
      parameters:
        - in: body
          name: alias
          description: The new alias to create
          schema:
            $ref: '#/definitions/Alias'
      responses:
        '201':
          description: Created
  '/cloudmesh/alias/{name}':
    get:
      description: Returns an alias
      operationId: get_alias_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: alias info
          schema:
            $ref: '#/definitions/Alias'
definitions:
  Alias:
    type: object
    description: the alias
    properties:
      name:
        type: string
        description: The name of the alias
      origin:
        type: string
        description: The original object name
\end{verbatim}

\hypertarget{variables}{%
\subsubsection{Variables}\label{variables}}

Variables are used to store simple values. Each variable can have a
type, which is also provided as demonstrated in the object below. The
variable value format is defined as string to allow maximal probability.

\begin{itemize}
\tightlist
\item
  TODO: assign and review
\end{itemize}

\hypertarget{properties-variables}{%
\paragraph{Properties Variables}\label{properties-variables}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & name of the variable\tabularnewline
value & string & type of the variable\tabularnewline
kind & string & value of the variable\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-5}{%
\paragraph{Paths}\label{paths-5}}

\hypertarget{cloudmeshvariables}{%
\subparagraph{/cloudmesh/variables}\label{cloudmeshvariables}}

GET /cloudmesh/variables

Returns all variabless

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & variables info &
\protect\hyperlink{variables}{Variables}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/variables

Create a new variables

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
variables & body & The new variables to create & False &
\protect\hyperlink{variables}{Variables}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshvariablesname}{%
\subparagraph{/cloudmesh/variables/\{name\}}\label{cloudmeshvariablesname}}

GET /cloudmesh/variables/\{name\}

Returns a variables

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & variables info &
\protect\hyperlink{variables}{Variables}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & Name of the variable & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{variables.yaml}{%
\paragraph{variables.yaml}\label{variables.yaml}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.1
  title: variables
  description: |-
  
    Variables are used to store simple values. Each variable can have
    a type, which is also provided as demonstrated in the object
    below. The variable value format is defined as string to allow
    maximal probability.

    * TODO: assign and review
    
  termsOfService: 'https://github.com/cloudmesh-community/nist/blob/master/LICENSE.txt'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/variables:
    get:
      description: Returns all variabless
      operationId: get_variables
      produces:
        - application/json
      responses:
        '200':
          description: variables info
          schema:
            $ref: '#/definitions/Variables'
    put:
      description: Create a new variables
      operationId: add_variables
      parameters:
        - in: body
          name: variables
          description: The new variables to create
          schema:
            $ref: '#/definitions/Variables'
      responses:
        '201':
          description: Created
  '/cloudmesh/variables/{name}':
    get:
      description: Returns a variables
      operationId: get_variables_by_name
      parameters:
        - name: name
          description: Name of the variable
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: variables info
          schema:
            $ref: '#/definitions/Variables'
definitions:
  Variables:
    type: object
    description: the variables
    properties:
      name:
        type: string
        description: name of the variable
      value:
        type: string
        description: type of the variable
      kind:
        type: string
        description: value of the variable
\end{verbatim}

\hypertarget{default}{%
\subsubsection{Default}\label{default}}

A default is a special variable that has a context associated with it.
This allows one to define values that can be easily retrieved based on
the associated context. For example, a default could be the image name
for a cloud where the context is defined by the cloud name.

\begin{itemize}
\tightlist
\item
  TODO: assign for review and improvement
\end{itemize}

\hypertarget{properties-defaults}{%
\paragraph{Properties Defaults}\label{properties-defaults}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & name of the default\tabularnewline
value & string & type of the default\tabularnewline
kind & string & value of the default\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-6}{%
\paragraph{Paths}\label{paths-6}}

\hypertarget{cloudmeshdefaults}{%
\subparagraph{/cloudmesh/defaults}\label{cloudmeshdefaults}}

GET /cloudmesh/defaults

Returns all defaults

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & default info & \protect\hyperlink{default}{Default}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/defaults

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
default & body & The new default to create & False &
\protect\hyperlink{default}{Default}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshdefaultname}{%
\subparagraph{/cloudmesh/default/\{name\}}\label{cloudmeshdefaultname}}

GET /cloudmesh/default/\{name\}

Returns a default

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & default info & \protect\hyperlink{default}{Default}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{default.yaml}{%
\paragraph{default.yaml}\label{default.yaml}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.2
  date: 10-30-2018
  title: default
  description: |-
  
    A default is a special variable that has a context associated with
    it. This allows one to define values that can be easily retrieved
    based on the associated context. For example, a default could be
    the image name for a cloud where the context is defined by the
    cloud name.

    * TODO: assign for review and improvement
    
  termsOfService: 'https://github.com/cloudmesh-community/nist/blob/master/LICENSE.txt'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/defaults:
    get:
      description: Returns all defaults
      operationId: get_default
      produces:
        - application/json
      responses:
        '200':
          description: default info
          schema:
            $ref: '#/definitions/Default'
    put:
      summary: Create a new default
      operationId: add_default
      parameters:
        - in: body
          name: default
          description: The new default to create
          schema:
            $ref: '#/definitions/Default'
      responses:
        '201':
          description: Created
  '/cloudmesh/default/{name}':
    get:
      description: Returns a default
      operationId: get_default_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: default info
          schema:
            $ref: '#/definitions/Default'
definitions:
  Defaults:
    type: object
    description: the defaults
    properties:
      name:
        type: string
        description: name of the default
      value:
        type: string
        description: type of the default
      kind:
        type: string
        description: value of the default
\end{verbatim}

\hypertarget{data-management}{%
\subsection{Data Management}\label{data-management}}

\hypertarget{database}{%
\subsubsection{Database}\label{database}}

A database could have a name, an endpoint (e.g., host, port), and a
protocol used (e.g., SQL, mongo).

\begin{itemize}
\tightlist
\item
  TODO: assign for review and improvement
\end{itemize}

\hypertarget{properties-database}{%
\paragraph{Properties Database}\label{properties-database}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & name of the database\tabularnewline
endpoint & string & endpoint of the database\tabularnewline
kind & string & the kind of the database\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-7}{%
\paragraph{Paths}\label{paths-7}}

\hypertarget{cloudmeshdatabases}{%
\subparagraph{/cloudmesh/databases}\label{cloudmeshdatabases}}

GET /cloudmesh/databases

Returns all databases

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & database info &
\protect\hyperlink{database}{Database}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/databases

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
database & body & The new database to create & False &
\protect\hyperlink{database}{Database}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshdatabasename}{%
\subparagraph{/cloudmesh/database/\{name\}}\label{cloudmeshdatabasename}}

GET /cloudmesh/database/\{name\}

Returns a database

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & database info &
\protect\hyperlink{database}{Database}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{database.yaml}{%
\paragraph{database.yaml}\label{database.yaml}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.2
  date: 10-30-2018
  title: database
  description: |-
  
    A database could have a name, an endpoint (e.g., host, port),
    and a protocol used (e.g., SQL, mongo).

    * TODO: assign for review and improvement
    
  termsOfService: 'http://bin.io/terms/'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/databases:
    get:
      description: Returns all databases
      operationId: get_database
      produces:
        - application/json
      responses:
        '200':
          description: database info
          schema:
            $ref: '#/definitions/Database'
    put:
      summary: Create a new database
      operationId: add_database
      parameters:
        - in: body
          name: database
          description: The new database to create
          schema:
            $ref: '#/definitions/Database'
      responses:
        '201':
          description: Created
  '/cloudmesh/database/{name}':
    get:
      description: Returns a database
      operationId: get_database_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: database info
          schema:
            $ref: '#/definitions/Database'
definitions:
  Database:
    type: object
    description: the database
    properties:
      name:
        type: string
        description: name of the database
      endpoint:
        type: string
        description: endpoint of the database
      kind:
        type: string
        description: the kind of the database
\end{verbatim}

\hypertarget{virtual-directory}{%
\subsubsection{Virtual Directory}\label{virtual-directory}}

A virtual directory is a collection of files or replicas of the files. A
virtual directory can contain a number of entities including files,
streams, and other virtual directories as part of a collection. The
element in the collection can either be defined by uuid or by name.

\hypertarget{properties-unauthorizederror}{%
\paragraph{Properties
UnauthorizedError}\label{properties-unauthorizederror}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
code & string & Code form of the error\tabularnewline
message & string & Human readable form of the error\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{properties-virtualdirectory}{%
\paragraph{Properties
Virtualdirectory}\label{properties-virtualdirectory}}

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.17\columnwidth}\raggedright
Property\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
Type\strut
\end{minipage} & \begin{minipage}[b]{0.58\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.17\columnwidth}\raggedright
name\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
The name of the virtual directory\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
description\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
description of the virtual directory\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
host\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
remote host of the virtual directory\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
location\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
remote location, e.g., a directory with full path on a host\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
protocol\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
access protocol, e.g., HTTP, FTP, SSH, etc.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
credential\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
object\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
credential to access, e.g., username, password\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-8}{%
\paragraph{Paths}\label{paths-8}}

\hypertarget{cloudmeshvirtualdirectory}{%
\subparagraph{/cloudmesh/virtualdirectory}\label{cloudmeshvirtualdirectory}}

GET /cloudmesh/virtualdirectory

Returns all virtualdirectorys

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & virtualdirectory info &
\protect\hyperlink{virtualdirectory}{Virtualdirectory}\tabularnewline
\bottomrule
\end{longtable}

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
401 & unauthorized error &
\protect\hyperlink{unauthorizederror}{UnauthorizedError}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/virtualdirectory

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.14\columnwidth}\raggedright
Name\strut
\end{minipage} & \begin{minipage}[b]{0.07\columnwidth}\raggedright
Located in\strut
\end{minipage} & \begin{minipage}[b]{0.27\columnwidth}\raggedright
Description\strut
\end{minipage} & \begin{minipage}[b]{0.08\columnwidth}\raggedright
Required\strut
\end{minipage} & \begin{minipage}[b]{0.29\columnwidth}\raggedright
Schema\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.14\columnwidth}\raggedright
virtualdirectory\strut
\end{minipage} & \begin{minipage}[t]{0.07\columnwidth}\raggedright
body\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\raggedright
The new virtualdirectory to create\strut
\end{minipage} & \begin{minipage}[t]{0.08\columnwidth}\raggedright
False\strut
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright
\protect\hyperlink{virtualdirectory}{Virtualdirectory}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshvirtualdirectoryname}{%
\subparagraph{/cloudmesh/virtualdirectory/\{name\}}\label{cloudmeshvirtualdirectoryname}}

GET /cloudmesh/virtualdirectory/\{name\}

Returns a virtualdirectory

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & virtualdirectory info &
\protect\hyperlink{virtualdirectory}{Virtualdirectory}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{virtualdirectory.yaml}{%
\paragraph{virtualdirectory.yaml}\label{virtualdirectory.yaml}}

\begin{verbatim}
---
swagger: '2.0'
info:
  version: 3.0.3
  date: 06-11-2018
  title: virtualdirectory
  description: |-
  
    A virtual directory is a collection of files or replicas of the
    files.  A virtual directory can contain a number of entities
    including files, streams, and other virtual directories as part of
    a collection.  The element in the collection can either be defined
    by uuid or by name.

  termsOfService: 'http://bin.io/terms/'
  contact:
    name: Cloudmesh RESTful Virtual Directory Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/virtualdirectory:
    get:
      tags:
        - "virtualdirectory"
      description: Returns all virtualdirectorys
      operationId: get_virtualdirectory
      produces:
        - application/json
      security:
        - httpbasic: []
      responses:
        '200':
          description: virtualdirectory info
          schema:
            $ref: '#/definitions/Virtualdirectory'
        '401':
          description: unauthorized error
          schema:
            $ref: '#/definitions/UnauthorizedError'
    put:
      tags:
        - "virtualdirectory"
      summary: Create a new virtualdirectory
      operationId: add_virtualdirectory
      parameters:
        - in: body
          name: virtualdirectory
          description: The new virtualdirectory to create
          schema:
            $ref: '#/definitions/Virtualdirectory'
      security:
        - apikey: []
          apisecret: []
      responses:
        '201':
          description: Created
  '/cloudmesh/virtualdirectory/{name}':
    get:
      tags:
        - "virtualdirectory"
      description: Returns a virtualdirectory
      operationId: get_virtualdirectory_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      security:
        - httpbasic: []
      responses:
        '200':
          description: virtualdirectory info
          schema:
            $ref: '#/definitions/Virtualdirectory'
definitions:
  UnauthorizedError:
    type: object
    description: A specific error
    properties:
      code:
        type: string
        description: Code form of the error
      message:
        type: string
        description: Human readable form of the error
  Virtualdirectory:
    type: "object"
    description: the virtualdirectory
    properties:
      name:
        description: The name of the virtual directory
        type: "string"
      description:
        description: description of the virtual directory
        type: "string"
      host:
        description: remote host of the virtual directory
        type: "string"
      location:
        description: remote location, e.g., a directory with full path on a host
        type: "string"
      protocol:
        description: access protocol, e.g., HTTP, FTP, SSH, etc.
        type: "string"
      credential:
        description: credential to access, e.g., username, password
        type: "object"
\end{verbatim}

\hypertarget{file}{%
\subsubsection{File}\label{file}}

A file is a computer resource allowing storage of data that is being
processed. The interface to a file provides the mechanism to
appropriately locate a file in a distributed system. File identification
includes the name, endpoint, checksum, and size. Additional parameters,
such as the last access time, could also be stored. The interface only
describes the location of the file. The file object has name, endpoint
(location), size in GB, MB, Byte, checksum for integrity check, and last
accessed timestamp.

\begin{itemize}
\tightlist
\item
  TODO: assign for review and improvement
\end{itemize}

\hypertarget{properties-file}{%
\paragraph{Properties File}\label{properties-file}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & the name of the file\tabularnewline
endpoint & string & The location of the file\tabularnewline
checksum & string & The checksum of the file\tabularnewline
size & integer & The size of the file in byte\tabularnewline
timestamp & timestamp & The timestamp\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-9}{%
\paragraph{Paths}\label{paths-9}}

\hypertarget{cloudmeshfiles}{%
\subparagraph{/cloudmesh/files}\label{cloudmeshfiles}}

GET /cloudmesh/files

Returns all files

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & file info & \protect\hyperlink{file}{File}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/files

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
file & body & The new file to create & False &
\protect\hyperlink{file}{File}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshfilename}{%
\subparagraph{/cloudmesh/file/\{name\}}\label{cloudmeshfilename}}

GET /cloudmesh/file/\{name\}

Returns a file

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & file info & \protect\hyperlink{file}{File}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{file.yaml}{%
\paragraph{file.yaml}\label{file.yaml}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.2
  date: 10-30-2018
  title: file
  description: |-
  
    A file is a computer resource allowing storage of data that is
    being processed. The interface to a file provides the mechanism to
    appropriately locate a file in a distributed system. File
    identification includes the name, endpoint, checksum, and
    size. Additional parameters, such as the last access time, could
    also be stored. The interface only describes the location of the
    file.  The file object has name, endpoint (location), size in GB,
    MB, Byte, checksum for integrity check, and last accessed
    timestamp.

    * TODO: assign for review and improvement
    
  termsOfService: 'http://bin.io/terms/'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/files:
    get:
      description: Returns all files
      operationId: get_file
      produces:
        - application/json
      responses:
        '200':
          description: file info
          schema:
            $ref: '#/definitions/File'
    put:
      summary: Create a new file
      operationId: add_file
      parameters:
        - in: body
          name: file
          description: The new file to create
          schema:
            $ref: '#/definitions/File'
      responses:
        '201':
          description: Created
  '/cloudmesh/file/{name}':
    get:
      description: Returns a file
      operationId: get_file_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: file info
          schema:
            $ref: '#/definitions/File'
definitions:
  File:
    type: object
    description: the file
    properties:
      name:
        type: string
        description: the name of the file
      endpoint:
        type: string
        description: The location of the file
      endpoint:
        type: string
        description: The location of the file
      checksum:
        type: string
        description: The checksum of the file
      size:
        type: integer
        description: The size of the file in byte
      timestamp:
        type: timestamp
        description: The timestamp

#        "name": "report.dat",
#        "endpoint": "file://gregor@machine.edu:/data/report.dat",
#        "checksum": {"sha256":"c01b39c7a35ccc ....... ebfeb45c69f08e17dfe3ef375a7b"},
#        "accessed": "1.1.2017:05:00:00:EST",
#        "created": "1.1.2017:05:00:00:EST",
#        "modified": "1.1.2017:05:00:00:EST",
#       "size": ["GB", "Byte"]
\end{verbatim}

\hypertarget{replica}{%
\subsubsection{Replica}\label{replica}}

In many distributed systems, it is important that a file can be
replicated among different systems to provide faster access. It is
important to provide a mechanism to trace the pedigree of the file while
pointing to its original source. A replica can be applied to all data
types introduced in this document.

\begin{itemize}
\tightlist
\item
  TODO: assign and improve
\end{itemize}

\hypertarget{properties-replica}{%
\paragraph{Properties Replica}\label{properties-replica}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & the name of the replica\tabularnewline
filename & the original name of the file & the original
filename\tabularnewline
endpoint & string & The location of the file\tabularnewline
checksum & string & The checksum of the file\tabularnewline
size & integer & The size of the file in byte\tabularnewline
timestamp & timestamp & The timestamp\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-10}{%
\paragraph{Paths}\label{paths-10}}

\hypertarget{cloudmeshreplicas}{%
\subparagraph{/cloudmesh/replicas}\label{cloudmeshreplicas}}

GET /cloudmesh/replicas

Returns all replicas

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & replica info & \protect\hyperlink{replica}{Replica}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/replicas

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
replica & body & The new replica to create & False &
\protect\hyperlink{replica}{Replica}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshreplicaname}{%
\subparagraph{/cloudmesh/replica/\{name\}}\label{cloudmeshreplicaname}}

GET /cloudmesh/replica/\{name\}

Returns a replica

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & replica info & \protect\hyperlink{replica}{Replica}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{replica.yaml}{%
\paragraph{replica.yaml}\label{replica.yaml}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.2
  date: 10-30-2018
  title: replica
  description: |-
  
    In many distributed systems, it is important that a file can be
    replicated among different systems to provide faster access. It is
    important to provide a mechanism to trace the pedigree of the file
    while pointing to its original source. A replica can be applied to
    all data types introduced in this document.

    * TODO: assign and improve
    
  termsOfService: 'http://bin.io/terms/'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/replicas:
    get:
      description: Returns all replicas
      operationId: get_replica
      produces:
        - application/json
      responses:
        '200':
          description: replica info
          schema:
            $ref: '#/definitions/Replica'
    put:
      summary: Create a new replica
      operationId: add_replica
      parameters:
        - in: body
          name: replica
          description: The new replica to create
          schema:
            $ref: '#/definitions/Replica'
      responses:
        '201':
          description: Created
  '/cloudmesh/replica/{name}':
    get:
      description: Returns a replica
      operationId: get_replica_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: replica info
          schema:
            $ref: '#/definitions/Replica'
definitions:
  Replica:
    type: object
    description: the replica
    properties:
      name:
        type: string
        description: the name of the replica
      filename:
        type: the original name of the file
        description: the original filename
      endpoint:
        type: string
        description: The location of the file
      checksum:
        type: string
        description: The checksum of the file
      size:
        type: integer
        description: The size of the file in byte
      timestamp:
        type: timestamp
        description: The timestamp
\end{verbatim}

\hypertarget{compute-management---virtual-clutsers}{%
\subsection{Compute Management - Virtual
Clutsers}\label{compute-management---virtual-clutsers}}

\hypertarget{virtual-cluster}{%
\subsubsection{Virtual Cluster}\label{virtual-cluster}}

Virtual Cluster example

\hypertarget{properties-virtualcluster}{%
\paragraph{Properties VirtualCluster}\label{properties-virtualcluster}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & The name of the virtual cluster\tabularnewline
description & string & A description of the virtual
cluster\tabularnewline
nnodes & integer & number of nodes of the virtual cluster\tabularnewline
owner & string & owner of the virtual cluster\tabularnewline
fe & & Front-end node of the virtual cluster\tabularnewline
nodes & array{[}\#/definitions/Node{]} & List of nodes of the virtual
cluster\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{properties-node}{%
\paragraph{Properties Node}\label{properties-node}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & name of the node\tabularnewline
state & string & power state of the node\tabularnewline
ncpu & integer & number of virtual CPUs of the node\tabularnewline
ram & string & RAM size of the node\tabularnewline
disk & string & Disk size of the node\tabularnewline
nics & array{[}\#/definitions/NIC{]} & List of network interfaces of the
node\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{properties-nic}{%
\paragraph{Properties NIC}\label{properties-nic}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
mac & string & MAC address of the node\tabularnewline
ip & string & IP address of the node\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-11}{%
\paragraph{Paths}\label{paths-11}}

\hypertarget{cloudmeshvirtualclustervirtualcluster}{%
\subparagraph{/cloudmesh/virtualcluster/virtualcluster}\label{cloudmeshvirtualclustervirtualcluster}}

GET /cloudmesh/virtualcluster/virtualcluster

Returns all virtualcluster

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & profile info &
\protect\hyperlink{virtualcluster}{VirtualCluster}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/virtualcluster/virtualcluster

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
virtualcluster & body & The new virtualcluster to create & False &
\protect\hyperlink{virtualcluster}{VirtualCluster}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshvirtualclustervirtualclustervirtualclustername}{%
\subparagraph{/cloudmesh/virtualcluster/virtualcluster/\{virtualclustername\}}\label{cloudmeshvirtualclustervirtualclustervirtualclustername}}

GET /cloudmesh/virtualcluster/virtualcluster/\{virtualclustername\}

Returns a virtualcluster by its name

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & virtualcluster info &
\protect\hyperlink{virtualcluster}{VirtualCluster}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
virtualclustername & path & ERROR: description missing & True
&\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshvirtualclustervirtualclustervirtualclusternamefe}{%
\subparagraph{/cloudmesh/virtualcluster/virtualcluster/\{virtualclustername\}/fe}\label{cloudmeshvirtualclustervirtualclustervirtualclusternamefe}}

GET /cloudmesh/virtualcluster/virtualcluster/\{virtualclustername\}/fe

Returns the front-end node info of the specified virtualcluster

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & virtualcluster front-end info &
\protect\hyperlink{node}{Node}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
virtualclustername & path & ERROR: description missing & True
&\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshvirtualclustervirtualclustervirtualclusternamenodename}{%
\subparagraph{/cloudmesh/virtualcluster/virtualcluster/\{virtualclustername\}/\{nodename\}}\label{cloudmeshvirtualclustervirtualclustervirtualclusternamenodename}}

GET
/cloudmesh/virtualcluster/virtualcluster/\{virtualclustername\}/\{nodename\}

Returns the specified node info of the specified virtualcluster

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & virtualcluster node info &
\protect\hyperlink{node}{Node}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
virtualclustername & path & ERROR: description missing & True
&\tabularnewline
nodename & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{vc.yaml}{%
\paragraph{vc.yaml}\label{vc.yaml}}

\begin{verbatim}
---
swagger: "2.0"
info:
  version: 3.0.3
  date: 06-11-2018
  title: "Virtual Cluster"
  description: |-

    Virtual Cluster example
    
  termsOfService: "https://github.com/cloudmesh-community/nist/blob/master/LICENSE.txt"
  contact:
    name: "Cloudmesh REST Service Example"
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: "Apache"
host: "localhost:8080"
schemes:
  - "http"
consumes:
  - "application/json"
produces:
  - "application/json"
paths:
  /cloudmesh/virtualcluster/virtualcluster:
    get:
      tags:
        - "virtualcluster"
      description: "Returns all virtualcluster"
      operationId: get_virtualcluster
      produces:
        - "application/json"
      responses:
        "200":
          description: "profile info"
          schema:
            $ref: "#/definitions/VirtualCluster"
    put:
      tags:
        - "virtualcluster"
      summary: "Create a new virtualcluster"
      operationId: add_virtualcluster
      parameters:
        - in: body
          name: virtualcluster
          description: "The new virtualcluster to create"
          schema:
            $ref: "#/definitions/VirtualCluster"
      responses:
        "201":
          description: Created
  /cloudmesh/virtualcluster/virtualcluster/{virtualclustername}:
    get:
      tags:
        - "virtualcluster"
      description: "Returns a virtualcluster by its name"
      operationId: getVirtualclusterByName
      parameters:
        - name: virtualclustername
          in: path
          required: true
          type: string
      produces:
        - "application/json"
      responses:
        "200":
          description: "virtualcluster info"
          schema:
            $ref: "#/definitions/VirtualCluster"
  /cloudmesh/virtualcluster/virtualcluster/{virtualclustername}/fe:
    get:
      tags:
        - "virtualcluster"
      description: "Returns the front-end node info of the specified virtualcluster"
      operationId: getVirtualclusterFeByName
      parameters:
        - name: virtualclustername
          in: path
          required: true
          type: string
      produces:
        - "application/json"
      responses:
        "200":
          description: "virtualcluster front-end info"
          schema:
            $ref: "#/definitions/Node"
  /cloudmesh/virtualcluster/virtualcluster/{virtualclustername}/{nodename}:
    get:
      tags:
        - "virtualcluster"
      description: "Returns the specified node info of the specified virtualcluster"
      operationId: getVirtualclusterNodeByName
      parameters:
        - name: virtualclustername
          in: path
          required: true
          type: string
        - name: nodename
          in: path
          required: true
          type: string
      produces:
        - "application/json"
      responses:
        "200":
          description: "virtualcluster node info"
          schema:
            $ref: "#/definitions/Node"
definitions:
  VirtualCluster:
    type: "object"
    properties:
      name:
        description: The name of the virtual cluster
        type: "string"
      description:
        type: "string"
        description: A description of the virtual cluster
      nnodes:
        type: "integer"
        description: number of nodes of the virtual cluster
      owner:
        type: "string"
        description: owner of the virtual cluster
      fe:
        description: Front-end node of the virtual cluster
        $ref: "#/definitions/Node"
      nodes:
        description: List of nodes of the virtual cluster
        type: array
        items:
          $ref: "#/definitions/Node"
  Node:
    type: "object"
    properties:
      name:
        type: "string"
        description: name of the node
      state:
        type: "string"
        description: power state of the node
      ncpu:
        type: "integer"
        description: number of virtual CPUs of the node
      ram:
        type: "string"
        description: RAM size of the node
      disk:
        type: "string"
        description: Disk size of the node
      nics:
        type: "array"
        description: List of network interfaces of the node
        items:
          $ref: "#/definitions/NIC"
  NIC:
    type: "object"
    properties:
      mac:
        type: "string"
        description: MAC address of the node
      ip:
        type: "string"
        description: IP address of the node
\end{verbatim}

\hypertarget{scheduler}{%
\subsubsection{Scheduler}\label{scheduler}}

A service to store scheduler, value, type information. All of them are
stored as Strings.

\begin{itemize}
\tightlist
\item
  TODO: assign and improve
\end{itemize}

\hypertarget{properties-scheduler}{%
\paragraph{Properties Scheduler}\label{properties-scheduler}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & name of the scheduler\tabularnewline
value & string & value of the scheduler\tabularnewline
kind & string & the scheduler kind or type\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-12}{%
\paragraph{Paths}\label{paths-12}}

\hypertarget{cloudmeshschedulers}{%
\subparagraph{/cloudmesh/schedulers}\label{cloudmeshschedulers}}

GET /cloudmesh/schedulers

Returns all schedulers

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & scheduler info &
\protect\hyperlink{scheduler}{Scheduler}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/schedulers

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
scheduler & body & The new scheduler to create & False &
\protect\hyperlink{scheduler}{Scheduler}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshschedulername}{%
\subparagraph{/cloudmesh/scheduler/\{name\}}\label{cloudmeshschedulername}}

GET /cloudmesh/scheduler/\{name\}

Returns a scheduler

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & scheduler info &
\protect\hyperlink{scheduler}{Scheduler}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{scheduler.yaml}{%
\subsubsection{scheduler.yaml}\label{scheduler.yaml}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.2
  date: 10-30-2018
  title: scheduler
  description: |-
  
    A service to store scheduler, value, type information. All of them
    are stored as Strings.

    * TODO: assign and improve
    
  termsOfService: 'https://github.com/cloudmesh-community/nist/blob/master/LICENSE.txt'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/schedulers:
    get:
      description: Returns all schedulers
      operationId: get_scheduler
      produces:
        - application/json
      responses:
        '200':
          description: scheduler info
          schema:
            $ref: '#/definitions/Scheduler'
    put:
      summary: Create a new scheduler
      operationId: add_scheduler
      parameters:
        - in: body
          name: scheduler
          description: The new scheduler to create
          schema:
            $ref: '#/definitions/Scheduler'
      responses:
        '201':
          description: Created
  '/cloudmesh/scheduler/{name}':
    get:
      description: Returns a scheduler
      operationId: get_scheduler_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: scheduler info
          schema:
            $ref: '#/definitions/Scheduler'
definitions:
  Scheduler:
    type: object
    description: the scheduler
    properties:
      name:
        type: string
        description: name of the scheduler
      value:
        type: string
        description: value of the scheduler
      kind:
        type: string
        description: the scheduler kind or type
\end{verbatim}

\hypertarget{compute-management---virtual-machines}{%
\subsection{Compute Management - Virtual
Machines}\label{compute-management---virtual-machines}}

This section is planed for a future verion.

\hypertarget{image}{%
\subsubsection{Image}\label{image}}

Just a placeholder fix

\begin{itemize}
\tightlist
\item
  TODO: this is a demo of the to do line
\end{itemize}

\hypertarget{properties-image}{%
\paragraph{Properties Image}\label{properties-image}}

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.17\columnwidth}\raggedright
Property\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
Type\strut
\end{minipage} & \begin{minipage}[b]{0.58\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.17\columnwidth}\raggedright
id\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
A unique id for the image\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
name\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
The name of the image\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
tag\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
A tag that can be defined by the user for the image\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
description\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
A description for the image\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
cloud\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
A cloud provider for which the image is designed. If multiple are using
the image, they are passed along as space seperated strings\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
os\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
The OS of the image\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
osVersion\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
The OS version of the image\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
status\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
The status of the image\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
visibility\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
The visibility of the image\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
extra\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
string\strut
\end{minipage} & \begin{minipage}[t]{0.58\columnwidth}\raggedright
Extra object of the image\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-13}{%
\paragraph{Paths}\label{paths-13}}

\hypertarget{cloudmeshimage}{%
\subparagraph{/cloudmesh/image}\label{cloudmeshimage}}

GET /cloudmesh/image

Returns all general description images

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & abc info & \protect\hyperlink{abc}{Abc}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/image

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
abc & body & The new abc to create & False &
\protect\hyperlink{image}{Image}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshimagename}{%
\subparagraph{/cloudmesh/image/\{name\}}\label{cloudmeshimagename}}

GET /cloudmesh/image/\{name\}

Returns a general description of an image

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & abc info & \protect\hyperlink{image}{Image}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{image.yaml}{%
\paragraph{image.yaml}\label{image.yaml}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.2
  date: 10-30-2018
  title: abc
  description: |-
  
    Just a placeholder fix

    * TODO: this is a demo of the to do line
    
  termsOfService: 'http://bin.io/terms/'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist/spec/
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/image:
    get:
      description: Returns all general description images
      operationId: get_abc
      produces:
        - application/json
      responses:
        '200':
          description: abc info
          schema:
            $ref: '#/definitions/Abc'
    put:
      summary: Create a new image
      operationId: add_image
      parameters:
        - in: body
          name: abc
          description: The new abc to create
          schema:
            $ref: '#/definitions/Image'
      responses:
        '201':
          description: Created
  '/cloudmesh/image/{name}':
    get:
      description: Returns a general description of an image
      operationId: get_image_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: abc info
          schema:
            $ref: '#/definitions/Image'
definitions:
  Image:
    type: object
    properties:
      id:
        description: A unique id for the image      
        type: string
      name:
        description: The name of the image
        type: string
      tag:
        description: A tag that can be defined by the user for the image
        type: string
      description:
        description: A description for the image
        type: string
      cloud:
        description: A cloud provider for which the image is designed. If multiple are using the image, they are passed along as space seperated strings      
        type: string
      os:
        description: The OS of the image
        type: string
      osVersion:
        description: The OS version of the image
        type: string
      status:
        description: The status of the image
        type: string
      visibility:
        description: The visibility of the image                   
        type: string
      extra:
        description:  Extra object of the image                 
        type: string
\end{verbatim}

\hypertarget{flavor}{%
\subsubsection{Flavor}\label{flavor}}

The flavor specifies elementary information about the compute node, such
as memory and number of cores, as well as other attributes that can be
added. Flavors are essential to size a virtual cluster appropriately.

\hypertarget{properties-flavor}{%
\paragraph{Properties Flavor}\label{properties-flavor}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
name & string & name of the flavor\tabularnewline
label & string & a label that a user can set for this
flavor\tabularnewline
uuid & string & the uuid of the flavor\tabularnewline
ncpu & integer & number of cpus\tabularnewline
ram & integer & number of bytes used for the image in RAM\tabularnewline
disk & integer & number of bytes used for the disk\tabularnewline
bandwidth & string & the bandwidth\tabularnewline
price & string & price for the flavor\tabularnewline
cloud & string & name of the cloud this flavor is used\tabularnewline
cloud\_flavor\_id & string & an id used by the cloud\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-14}{%
\paragraph{Paths}\label{paths-14}}

\hypertarget{cloudmeshflavors}{%
\subparagraph{/cloudmesh/flavors}\label{cloudmeshflavors}}

GET /cloudmesh/flavors

Returns all flavors

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & flavor info & \protect\hyperlink{flavor}{Flavor}\tabularnewline
\bottomrule
\end{longtable}

PUT /cloudmesh/flavors

ERROR: missing

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
201 & Created &\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
flavor & body & The new flavor to create & False &
\protect\hyperlink{flavor}{Flavor}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{cloudmeshflavorname}{%
\subparagraph{/cloudmesh/flavor/\{name\}}\label{cloudmeshflavorname}}

GET /cloudmesh/flavor/\{name\}

Returns a flavor

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & flavor info & \protect\hyperlink{flavor}{Flavor}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
Name & Located in & Description & Required & Schema\tabularnewline
\midrule
\endhead
name & path & ERROR: description missing & True &\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{image.yaml-1}{%
\paragraph{image.yaml}\label{image.yaml-1}}

\begin{verbatim}
swagger: '2.0'
info:
  version: 3.0.3
  date: 10-30-2018
  title: flavor
  description: |-
  
    The flavor specifies elementary information about the compute
    node, such as memory and number of cores, as well as other
    attributes that can be added. Flavors are essential to size a
    virtual cluster appropriately.

  termsOfService: 'https://github.com/cloudmesh-community/nist/blob/master/LICENSE.txt'
  contact:
    name: Cloudmesh RESTful Service Example
    url: https://cloudmesh-community.github.io/nist
  license:
    name: Apache
host: 'localhost:8080'
schemes:
  - http
consumes:
  - application/json
produces:
  - application/json
paths:
  /cloudmesh/flavors:
    get:
      description: Returns all flavors
      operationId: get_flavor
      produces:
        - application/json
      responses:
        '200':
          description: flavor info
          schema:
            $ref: '#/definitions/Flavor'
    put:
      summary: Create a new flavor
      operationId: add_flavor
      parameters:
        - in: body
          name: flavor
          description: The new flavor to create
          schema:
            $ref: '#/definitions/Flavor'
      responses:
        '201':
          description: Created
  '/cloudmesh/flavor/{name}':
    get:
      description: Returns a flavor
      operationId: get_flavor_by_name
      parameters:
        - name: name
          in: path
          required: true
          type: string
      produces:
        - application/json
      responses:
        '200':
          description: flavor info
          schema:
            $ref: '#/definitions/Flavor'
definitions:
  Flavor:
    type: object
    description: the flavor
    properties:
      name:
        type: string
        description: name of the flavor
      label:
        type: string
        description: a label that a user can set for this flavor
      uuid:
        type: string
        description: the uuid of the flavor
      ncpu:
        type: integer
        description: number of cpus
      ram:
        type: integer
        description: number of bytes used for the image in RAM
      disk:
        type: integer
        description: number of bytes used for the disk
      bandwidth:
        type: string
        description: the bandwidth
      price:
        type: string
        description: price for the flavor
      cloud:
        type: string
        description: name of the cloud this flavor is used
      cloud_flavor_id:
        type: string
        description: an id used by the cloud

\end{verbatim}

\hypertarget{vm}{%
\subsubsection{Vm}\label{vm}}

A service to manage virtual machines

\hypertarget{properties-vm}{%
\paragraph{Properties VM}\label{properties-vm}}

\begin{longtable}[]{@{}lll@{}}
\toprule
Property & Type & Description\tabularnewline
\midrule
\endhead
provider & string & Name of the provider\tabularnewline
id & string & a unique id for the vm\tabularnewline
name & string & the name of the vm\tabularnewline
image & string & the image for the vm\tabularnewline
region & string & an optional region\tabularnewline
size & string & The size of the vm\tabularnewline
state & string & The state of the vm\tabularnewline
private\_ips & string & The private IPs\tabularnewline
public\_ips & string & The public IPS\tabularnewline
metadata & string & The meta data passed along to the VM\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{paths-15}{%
\paragraph{Paths}\label{paths-15}}

\hypertarget{vm-1}{%
\subparagraph{/vm}\label{vm-1}}

GET /vm

Returns the list of the vms

Responses

\begin{longtable}[]{@{}lll@{}}
\toprule
Code & Description & Schema\tabularnewline
\midrule
\endhead
200 & Listing the VMs & \protect\hyperlink{vm}{VM}\tabularnewline
\bottomrule
\end{longtable}

Parameters

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.10\columnwidth}\raggedright
Name\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\raggedright
Located in\strut
\end{minipage} & \begin{minipage}[b]{0.40\columnwidth}\raggedright
Description\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\raggedright
Required\strut
\end{minipage} & \begin{minipage}[b]{0.12\columnwidth}\raggedright
Schema\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.10\columnwidth}\raggedright
cloud\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
body\strut
\end{minipage} & \begin{minipage}[t]{0.40\columnwidth}\raggedright
specify the cloud from which we list, if ommitted all clouds are
returned.\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
False\strut
\end{minipage} & \begin{minipage}[t]{0.12\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{vm.yaml}{%
\paragraph{vm.yaml}\label{vm.yaml}}

\begin{verbatim}
swagger: "2.0"
info:
  version: 3.0.4
  date: 11-14-2018
  title: "Coludmesh VM"
  description: |-

    A service to manage virtual machines

  termsOfService: "https://github.com/cloudmesh-community/nist/blob/master/LICENSE.txt"
  contact:
    name: Gregor von Laszeewski
  license:
    name: "Apache"
host: "localhost:8080"
basePath: "/cloudmesh"
schemes:
  - "http"
consumes:
  - "application/json"
produces:
  - "application/json"
paths:
  /vm:
    get:
      tags:
        - "vm"
      operationId: vm_list
      description: "Returns the list of the vms"
      produces: 
        - "application/json"
      parameters:
        - name: "cloud"
          in: "body"
          type: string
          description: "specify the cloud from which we list, if ommitted all clouds are returned."
          required: false
      schema:
        $ref: "#/definitions/VM"
      responses: 
        "200":
          description: "Listing the VMs"
          schema: 
            $ref: "#/definitions/VM"
definitions:
  VM:
    type: "object"
    properties:
      provider:
        type: "string"
        description: Name of the provider    
      id:
        type: "string"
        description: a unique id for the vm
      name:
        type: "string"
        description: the name of the vm
      image:
        type: "string"
        description: the image for the vm
      region:
        type: "string"
        description: an optional region
      size:
        type: "string"
        description: The size of the vm
      state:
        type: "string"
        description: The state of the vm
      private_ips:
        type: "string"   # will be changed to array
        description: The private IPs
      public_ips:
        type: "string"   # will be changed to array
        description: The public IPS
      metadata:
        type: "string"   # will be changed to dict
        description: The meta data passed along to the VM
        

\end{verbatim}

\hypertarget{compute-management---containers}{%
\subsection{Compute Management -
Containers}\label{compute-management---containers}}

This section is planed for a future verion.

\hypertarget{compute-management---functions}{%
\subsection{Compute Management -
Functions}\label{compute-management---functions}}

This section is planed for a future verion.

\hypertarget{others}{%
\subsection{Others}\label{others}}

Please notify us if you like to add other specifications.

\hypertarget{status-codes-and-error-responses}{%
\section{Status Codes and Error
Responses}\label{status-codes-and-error-responses}}

In case of an error or a successful response, the response header
contains a HTTP code (see \url{https://tools.ietf.org/html/rfc7231}).
The response body usually contains the following:

\begin{itemize}
\item
  The HTTP response code;
\item
  An accompanying message for the HTTP response code; and
\item
  A field or object where the error occurred.
\end{itemize}

Table 1: HTTP Response Codes

\begin{longtable}[]{@{}ll@{}}
\toprule
HTTP Response & Description Code\tabularnewline
\midrule
\endhead
200 & \emph{OK} success code, for GET or HEAD request.\tabularnewline
201 & \emph{Created} success code, for POST request.\tabularnewline
204 & \emph{No Content} success code, for DELETE request.\tabularnewline
300 & The value returned when an external ID exists in more than one
record.\tabularnewline
304 & The request content has not changed since a specified date and
time.\tabularnewline
400 & The request could not be understood.\tabularnewline
401 & The session ID or OAuth token used has expired or is
invalid.\tabularnewline
403 & The request has been refused.\tabularnewline
404 & The requested resource could not be found.\tabularnewline
405 & The method specified in the Request-Line isn't allowed for the
resource specified in the URI.\tabularnewline
415 & The entity in the request is in a format that's not supported by
the specified method.\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{acronyms-and-terms}{%
\section{Acronyms and Terms}\label{acronyms-and-terms}}

The following acronyms and terms are used in this volume.

\textbf{ACID} - Atomicity, Consistency, Isolation, Durability

\textbf{API} - Application Programming Interface

\begin{description}
\item[ASCII]
American Standard Code for Information Interchange
\item[BASE]
Basically Available, Soft state, Eventual consistency
\item[Container]
See
\url{http://csrc.nist.gov/publications/drafts/800-180/sp800-180_draft.pdf}
\item[Cloud Computing]
The practice of using a network of remote servers hosted on the Internet
to store, manage, and process data, rather than a local server or a
personal computer. See
\url{http://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf}.
\item[DevOps]
A clipped compound of software DEVelopment and information technology
OPerationS
\item[Deployment]
The action of installing software on resources
\item[HTTP]
HyperText Transfer Protocol HTTPS HTTP Secure
\item[Hybrid]
Cloud See
\url{http://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf}.
\item[IaaS]
Infrastructure as a Service SaaS Software as a Service
\item[ITL]
Information Technology Laboratory
\item[Microservice Architecture]
Is an approach to build applications based on many smaller modular
services. Each module supports a specific goal and uses a simple,
well-defined interface to communicate with other sets of services.
\item[NBD-PWG]
NIST Big Data Public Working Group
\item[NBDRA]
NIST Big Data Reference Architecture
\item[NBDRAI]
NIST Big Data Reference Architecture Interface
\item[NIST]
National Institute of Standards and Technology
\item[OS]
Operating System
\item[REST]
REpresentational State Transfer
\item[Replica]
A duplicate of a file on another resource to avoid costly transfer costs
in case of frequent access.
\item[Serverless Computing]
Serverless computing specifies the paradigm of function as a service
(FaaS). It is a cloud computing code execution model in which a cloud
provider manages the function deployment and utilization while clients
can utilize them. The charge model is based on execution of the function
rather than the cost to manage and host the VM or container.
\item[Software Stack]
A set of programs and services that are installed on a resource to
support applications.
\item[Virtual Filesysyem]
An abstraction layer on top of a distributed physical file system to
allow easy access to the files by the user or application.
\item[Virtual Machine]
A VM is a software computer that, like a physical computer, runs an
operating system and applications. The VM is composed of a set of
specification and configuration files and is backed by the physical
resources of a host.
\item[Virtual Cluster]
A virtual cluster is a software cluster that integrate either VMs,
containers, or physical resources into an agglomeration of compute
resources. A virtual cluster allows users to authenticate and authorize
to the virtual compute nodes to utilize them for calculations. Optional
high-level services that can be deployed on a virtual cluster may
simplify interaction with the virtual cluster or provide higher-level
services.
\item[Workflow]
The sequence of processes or tasks
\item[WWW]
World Wide Web
\end{description}

\hypertarget{bibliography}{%
\section{Bibliography}\label{bibliography}}

\begin{itemize}
\item
  {[}1{]} Cerberus. URL: \url{http://docs.python-cerberus.org/}.
\item
  {[}2{]} Eve Rest Service. Web Page. URL: \url{http://python-eve.org/}.
\item
  {[}3{]} Cloudmesh enhanced Eveengine. GitHub. URL:
  \url{https://github.com/cloudmesh/cloudmesh}. evegenie.
\item
  {[}4{]} Geoffrey C. Fox and Wo Chang. NIST Big Data Interoperability
  Framework: Volume 3, Use Cases and General Requirements. Special
  Publication (NIST SP) - 1500-3 1500-3, National Institute of
  Standards, 100 Bureau Drive, Gaithersburg, MD 20899, October 2015.
  URL:
  \url{http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1500-3.pdf},
  doi:NIST.SP.1500-3.
\item
  {[}5{]} Internet2. eduPerson Object Class Specification (201602).
  Internet2 Middleware Architecture Committee for Education, Directory
  Working Group internet2-mace-dir-eduperson-201602, Internet2, March

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \setcounter{enumi}{2015}
  \tightlist
  \item
    URL:
    \url{http://software.internet2.edu/eduperson/internet2-mace-dir-eduperson-201602.html}
  \end{enumerate}
\item
  {[}6{]} Orit Levin, David Boyd, and Wo Chang. NIST Big Data
  Interoperability Framework: Volume 6, Reference Architecture. Special
  Publication (NIST SP) - 1500-6 1500-6, National Institute of
  Standards, 100 Bureau Drive, Gaithersburg, MD 20899, October 2015.
  URL: \url{http://nvlpubs.nist.gov/nistpubs/}
  SpecialPublications/NIST.SP.1500-6.pdf, doi:NIST.SP.1500-6.
\item
  {[}7{]} NIST. Big Data Public Working Group (NBD-PWG). Web Page. URL:
  \url{https://bigdatawg.nist.gov/}.
\item
  {[}8{]} Arnab Roy, Mark Underwood, and Wo Chang. NIST Big Data
  Interoperability Framework: Volume 4, Security and Privacy. Special
  Publication (NIST SP) - 1500-4 1500-4, National Institute of
  Standards, 100 Bureau Drive, Gaithersburg, MD 20899, October 2015.
  URL:
  \url{http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1500-4.pdf},
  doi:NIST.SP.1500-4.
\item
  {[}9{]} Gregor von Laszewski. Cloudmesh client. GitHub. URL:
  \url{https://github.com/cloudmesh/client}.
\item
  {[}10{]} Gregor von Laszewski, Wo Chang, Fugang Wang, Badi Abdhul
  Wahid, Geoffrey C. Fox, Pratik Thakkar, Alicia Mara Zuniga-Alvarado,
  and Robert C. Whetsel. NIST Big Data Interoperability Framework:
  Volume 8, Reference Architecture Interfaces. Special Publication (NIST
  SP) - 1500-9 1500-9, National Institute of Standards, 100 Bureau
  Drive, Gaithersburg, MD 20899, October 2015. URL:
  \url{https://laszewski.github.io/papers/NIST.SP.1500-9-draft.pdf},
  doi:NIST.SP.1500-9.
\item
  {[}11{]} Gregor von Laszewski, Fugang Wang, Badi Abdul-Wahid, Hyungro
  Lee, Geoffrey C. Fox, and Wo Chang. Cloudmesh in support of the nist
  big data architecture framework. Technical report, Indiana University,
  Bloomington, IN 47408, USA, April 2017. URL:
  \url{https://laszewski.github.io/papers/vonLaszewski-nist.pdf}.
\end{itemize}

\end{document}
